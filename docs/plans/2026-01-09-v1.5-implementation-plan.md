# v1.5 "Live Intelligence" Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add live regime awareness with explicit confidence decomposition, expected-vs-realized tracking, and regime duration estimation.

**Architecture:** Three primitives layered on v1.0: (A) Decomposed confidence with `regime_distance_z`, (B) Accountability records with hysteresis FSM for regime transitions, (C) Duration stats from historical segmentation. All computation flows through existing recommend pipeline with new fields added to response.

**Tech Stack:** PostgreSQL (Supabase), Python 3.12, FastAPI, pytest, asyncpg

**Design Doc:** `docs/plans/2026-01-09-v1.5-live-intelligence-design.md`

---

## Phase 1: Database Schema

### Task 1.1: Create v1.5 Migration File

**Files:**
- Create: `migrations/019_v1_5_live_intelligence.sql`

**Step 1: Write migration with all 5 tables**

```sql
-- migrations/019_v1_5_live_intelligence.sql
-- v1.5 "Live Intelligence" schema additions
-- Design doc: docs/plans/2026-01-09-v1.5-live-intelligence-design.md

-- =============================================================================
-- Table 1: regime_cluster_stats
-- Feature centroids + variances per regime key (for distance_z scaling)
-- =============================================================================

CREATE TABLE IF NOT EXISTS regime_cluster_stats (
    strategy_entity_id UUID NOT NULL,
    timeframe TEXT NOT NULL,
    regime_key TEXT NOT NULL,
    regime_dims JSONB NOT NULL,

    n INT NOT NULL,
    feature_schema_version INT NOT NULL DEFAULT 1,
    feature_mean JSONB NOT NULL,
    feature_var JSONB NOT NULL,
    feature_min JSONB,
    feature_max JSONB,

    updated_at TIMESTAMPTZ DEFAULT now(),
    PRIMARY KEY (strategy_entity_id, timeframe, regime_key)
);

CREATE INDEX IF NOT EXISTS idx_cluster_stats_strategy_timeframe
    ON regime_cluster_stats(strategy_entity_id, timeframe);

COMMENT ON TABLE regime_cluster_stats IS 'v1.5: Feature centroids and variances per regime key for distance_z scaling';

-- =============================================================================
-- Table 2: regime_duration_stats
-- Duration distributions per regime key (for persistence estimation)
-- =============================================================================

CREATE TABLE IF NOT EXISTS regime_duration_stats (
    symbol TEXT NOT NULL,
    timeframe TEXT NOT NULL,
    regime_key TEXT NOT NULL,

    n_segments INT NOT NULL,
    median_duration_bars INT NOT NULL,
    p25_duration_bars INT NOT NULL,
    p75_duration_bars INT NOT NULL,

    updated_at TIMESTAMPTZ DEFAULT now(),
    PRIMARY KEY (symbol, timeframe, regime_key)
);

CREATE INDEX IF NOT EXISTS idx_duration_stats_timeframe_key
    ON regime_duration_stats(timeframe, regime_key);

COMMENT ON TABLE regime_duration_stats IS 'v1.5: Historical regime duration distributions for persistence estimation';

-- =============================================================================
-- Table 3: recommendation_records
-- Expectation contracts (long-lived, one active per symbol+strategy)
-- =============================================================================

CREATE TABLE IF NOT EXISTS recommendation_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    workspace_id UUID NOT NULL,
    strategy_entity_id UUID NOT NULL,
    symbol TEXT NOT NULL,
    timeframe TEXT NOT NULL,

    params_json JSONB NOT NULL,
    params_hash TEXT NOT NULL,

    regime_key_start TEXT NOT NULL,
    regime_dims_start JSONB NOT NULL,
    regime_features_start JSONB NOT NULL,

    schema_version INT NOT NULL DEFAULT 1,
    confidence_json JSONB NOT NULL,
    expected_baselines_json JSONB NOT NULL,

    status TEXT NOT NULL DEFAULT 'active',
    -- Status: active | superseded | inactive | closed

    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Only one active recommendation per symbol+strategy+workspace
CREATE UNIQUE INDEX IF NOT EXISTS idx_records_active_unique
    ON recommendation_records(workspace_id, strategy_entity_id, symbol, timeframe)
    WHERE status = 'active';

CREATE INDEX IF NOT EXISTS idx_records_workspace_status
    ON recommendation_records(workspace_id, status);

COMMENT ON TABLE recommendation_records IS 'v1.5: Expectation contracts for expected-vs-realized tracking';

-- =============================================================================
-- Table 4: recommendation_observations
-- Streaming realized metrics (append-only)
-- =============================================================================

CREATE TABLE IF NOT EXISTS recommendation_observations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    record_id UUID NOT NULL REFERENCES recommendation_records(id) ON DELETE CASCADE,
    ts TIMESTAMPTZ NOT NULL,

    bars_seen INT NOT NULL,
    trades_seen INT NOT NULL,
    realized_metrics_json JSONB NOT NULL,

    created_at TIMESTAMPTZ DEFAULT now(),

    UNIQUE (record_id, ts)
);

CREATE INDEX IF NOT EXISTS idx_observations_record_ts
    ON recommendation_observations(record_id, ts DESC);

COMMENT ON TABLE recommendation_observations IS 'v1.5: Streaming realized metrics for forward runs';

-- =============================================================================
-- Table 5: recommendation_evaluation_slices
-- Accountability checkpoints (immutable snapshots)
-- =============================================================================

CREATE TABLE IF NOT EXISTS recommendation_evaluation_slices (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    record_id UUID NOT NULL REFERENCES recommendation_records(id) ON DELETE CASCADE,

    slice_start_ts TIMESTAMPTZ NOT NULL,
    slice_end_ts TIMESTAMPTZ NOT NULL,

    trigger_type TEXT NOT NULL,
    -- Trigger: regime_change | milestone | manual

    regime_key_during TEXT NOT NULL,
    realized_summary_json JSONB NOT NULL,
    expected_summary_json JSONB NOT NULL,
    performance_surprise_z FLOAT,
    drift_flags_json JSONB,

    created_at TIMESTAMPTZ DEFAULT now()
);

CREATE INDEX IF NOT EXISTS idx_slices_record_end
    ON recommendation_evaluation_slices(record_id, slice_end_ts DESC);

CREATE INDEX IF NOT EXISTS idx_slices_trigger_type
    ON recommendation_evaluation_slices(trigger_type);

COMMENT ON TABLE recommendation_evaluation_slices IS 'v1.5: Accountability checkpoints on regime change or milestones';
```

**Step 2: Verify syntax**

Run: `cat migrations/019_v1_5_live_intelligence.sql | head -50`
Expected: First 50 lines of valid SQL

**Step 3: Commit**

```bash
git add migrations/019_v1_5_live_intelligence.sql
git commit -m "feat(db): add v1.5 live intelligence schema (5 tables)"
```

---

## Phase 2: Core Types & Utilities

### Task 2.1: Regime Key Utilities

**Files:**
- Create: `app/services/kb/regime_key.py`
- Test: `tests/unit/test_regime_key.py`

**Step 1: Write failing tests for canonical key generation**

```python
# tests/unit/test_regime_key.py
"""Tests for regime key canonicalization."""

import pytest
from app.services.kb.regime_key import (
    RegimeDims,
    canonicalize_regime_key,
    parse_regime_key,
    extract_marginal_keys,
    VALID_TREND_VALUES,
    VALID_VOL_VALUES,
)


class TestCanonicalizeRegimeKey:
    """Tests for canonicalize_regime_key()."""

    def test_basic_canonicalization(self):
        """Canonical key is sorted alphabetically by dimension."""
        dims = RegimeDims(trend="uptrend", vol="high_vol")
        assert canonicalize_regime_key(dims) == "trend=uptrend|vol=high_vol"

    def test_order_independent(self):
        """Same dims produce same key regardless of creation order."""
        dims1 = RegimeDims(trend="flat", vol="low_vol")
        dims2 = RegimeDims(vol="low_vol", trend="flat")
        assert canonicalize_regime_key(dims1) == canonicalize_regime_key(dims2)

    def test_all_combinations_valid(self):
        """All 9 combinations produce valid keys."""
        keys = set()
        for trend in VALID_TREND_VALUES:
            for vol in VALID_VOL_VALUES:
                dims = RegimeDims(trend=trend, vol=vol)
                key = canonicalize_regime_key(dims)
                assert key not in keys, f"Duplicate key: {key}"
                keys.add(key)
        assert len(keys) == 9

    def test_invalid_trend_raises(self):
        """Invalid trend value raises ValueError."""
        with pytest.raises(ValueError, match="Invalid trend"):
            RegimeDims(trend="bullish", vol="high_vol")

    def test_invalid_vol_raises(self):
        """Invalid vol value raises ValueError."""
        with pytest.raises(ValueError, match="Invalid vol"):
            RegimeDims(trend="uptrend", vol="extreme_vol")


class TestParseRegimeKey:
    """Tests for parse_regime_key()."""

    def test_roundtrip(self):
        """Parse inverts canonicalize."""
        dims = RegimeDims(trend="downtrend", vol="mid_vol")
        key = canonicalize_regime_key(dims)
        parsed = parse_regime_key(key)
        assert parsed == dims

    def test_invalid_format_raises(self):
        """Malformed key raises ValueError."""
        with pytest.raises(ValueError, match="Invalid regime key format"):
            parse_regime_key("uptrend|high_vol")  # Missing dimension names


class TestExtractMarginalKeys:
    """Tests for extract_marginal_keys()."""

    def test_extracts_both_marginals(self):
        """Returns both single-dimension marginal keys."""
        key = "trend=uptrend|vol=high_vol"
        marginals = extract_marginal_keys(key)
        assert set(marginals) == {"trend=uptrend", "vol=high_vol"}

    def test_marginals_are_valid_keys(self):
        """Marginal keys can be parsed (for backoff queries)."""
        key = "trend=flat|vol=low_vol"
        for marginal in extract_marginal_keys(key):
            # Should not raise
            assert "=" in marginal
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_regime_key.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write minimal implementation**

```python
# app/services/kb/regime_key.py
"""
Regime key utilities for v1.5 dimensional taxonomy.

Regime keys are canonical composites of fixed dimensions:
- trend: uptrend | downtrend | flat
- vol: low_vol | mid_vol | high_vol

Format: "trend=<value>|vol=<value>" (alphabetical dimension order)
"""

from dataclasses import dataclass
from typing import Literal

# Valid dimension values (v1.5 invariant)
VALID_TREND_VALUES = frozenset(["uptrend", "downtrend", "flat"])
VALID_VOL_VALUES = frozenset(["low_vol", "mid_vol", "high_vol"])

TrendValue = Literal["uptrend", "downtrend", "flat"]
VolValue = Literal["low_vol", "mid_vol", "high_vol"]


@dataclass(frozen=True)
class RegimeDims:
    """
    Regime dimensions (v1.5).

    Immutable to ensure consistent hashing.
    """
    trend: TrendValue
    vol: VolValue

    def __post_init__(self):
        if self.trend not in VALID_TREND_VALUES:
            raise ValueError(f"Invalid trend value: {self.trend}. Must be one of {VALID_TREND_VALUES}")
        if self.vol not in VALID_VOL_VALUES:
            raise ValueError(f"Invalid vol value: {self.vol}. Must be one of {VALID_VOL_VALUES}")

    def to_dict(self) -> dict:
        """Convert to JSON-serializable dict."""
        return {"trend": self.trend, "vol": self.vol}


def canonicalize_regime_key(dims: RegimeDims) -> str:
    """
    Generate canonical regime key from dimensions.

    Format: "trend=<value>|vol=<value>" (alphabetical order)

    Args:
        dims: Regime dimensions

    Returns:
        Canonical key string
    """
    # Alphabetical order: trend before vol
    return f"trend={dims.trend}|vol={dims.vol}"


def parse_regime_key(key: str) -> RegimeDims:
    """
    Parse canonical regime key into dimensions.

    Args:
        key: Canonical key string

    Returns:
        RegimeDims

    Raises:
        ValueError: If key format is invalid
    """
    parts = key.split("|")
    if len(parts) != 2:
        raise ValueError(f"Invalid regime key format: {key}. Expected 2 parts, got {len(parts)}")

    dims_dict = {}
    for part in parts:
        if "=" not in part:
            raise ValueError(f"Invalid regime key format: {key}. Part missing '=': {part}")
        dim_name, dim_value = part.split("=", 1)
        dims_dict[dim_name] = dim_value

    if "trend" not in dims_dict or "vol" not in dims_dict:
        raise ValueError(f"Invalid regime key format: {key}. Missing trend or vol dimension")

    return RegimeDims(trend=dims_dict["trend"], vol=dims_dict["vol"])


def extract_marginal_keys(key: str) -> list[str]:
    """
    Extract single-dimension marginal keys for backoff queries.

    Args:
        key: Canonical composite key

    Returns:
        List of marginal keys (e.g., ["trend=uptrend", "vol=high_vol"])
    """
    return key.split("|")
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/unit/test_regime_key.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/services/kb/regime_key.py tests/unit/test_regime_key.py
git commit -m "feat(kb): add regime key canonicalization utilities"
```

---

### Task 2.2: Hysteresis FSM

**Files:**
- Create: `app/services/kb/regime_fsm.py`
- Test: `tests/unit/test_regime_fsm.py`

**Step 1: Write failing tests for FSM behavior**

```python
# tests/unit/test_regime_fsm.py
"""Tests for regime stability FSM (hysteresis guard)."""

import pytest
from app.services.kb.regime_fsm import (
    RegimeFSM,
    FSMConfig,
    FSMState,
    RegimeTransitionEvent,
)


class TestFSMBasicBehavior:
    """Tests for basic FSM state transitions."""

    def test_initial_state(self):
        """FSM starts with no stable regime until first update."""
        fsm = RegimeFSM(config=FSMConfig())
        state = fsm.get_state()
        assert state.stable_regime_key is None
        assert state.candidate_regime_key is None
        assert state.candidate_count == 0

    def test_first_regime_immediately_stable(self):
        """First regime becomes stable immediately (no history to compare)."""
        fsm = RegimeFSM(config=FSMConfig(M=20))
        event = fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        state = fsm.get_state()
        assert state.stable_regime_key == "trend=uptrend|vol=high_vol"
        assert event is None  # No transition event for initialization

    def test_same_regime_clears_candidate(self):
        """Receiving same regime as stable clears any candidate."""
        fsm = RegimeFSM(config=FSMConfig(M=5))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # Start building candidate
        fsm.update("trend=flat|vol=high_vol", confidence=0.7)
        fsm.update("trend=flat|vol=high_vol", confidence=0.7)
        assert fsm.get_state().candidate_count == 2

        # Back to stable regime
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)
        assert fsm.get_state().candidate_count == 0
        assert fsm.get_state().candidate_regime_key is None


class TestFSMHysteresis:
    """Tests for hysteresis behavior (C_enter vs C_exit)."""

    def test_low_confidence_ignored(self):
        """Regime changes below C_exit are ignored as noise."""
        fsm = RegimeFSM(config=FSMConfig(M=5, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # Low confidence change should be ignored
        fsm.update("trend=flat|vol=high_vol", confidence=0.50)
        assert fsm.get_state().candidate_count == 0

    def test_candidate_builds_above_c_exit(self):
        """Regime changes above C_exit start building candidate."""
        fsm = RegimeFSM(config=FSMConfig(M=5, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # Above C_exit, candidate builds
        fsm.update("trend=flat|vol=high_vol", confidence=0.60)
        assert fsm.get_state().candidate_count == 1
        assert fsm.get_state().candidate_regime_key == "trend=flat|vol=high_vol"


class TestFSMTransitionConfirmation:
    """Tests for transition confirmation logic."""

    def test_transition_requires_m_bars(self):
        """Transition only confirms after M consecutive bars."""
        fsm = RegimeFSM(config=FSMConfig(M=3, C_enter=0.70, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # 2 bars is not enough
        fsm.update("trend=flat|vol=high_vol", confidence=0.75)
        fsm.update("trend=flat|vol=high_vol", confidence=0.75)
        assert fsm.get_state().stable_regime_key == "trend=uptrend|vol=high_vol"

        # 3rd bar triggers transition
        event = fsm.update("trend=flat|vol=high_vol", confidence=0.75)
        assert fsm.get_state().stable_regime_key == "trend=flat|vol=high_vol"
        assert event is not None
        assert event.from_key == "trend=uptrend|vol=high_vol"
        assert event.to_key == "trend=flat|vol=high_vol"

    def test_transition_requires_median_confidence(self):
        """Transition requires median confidence >= C_enter over M bars."""
        fsm = RegimeFSM(config=FSMConfig(M=3, C_enter=0.75, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # Candidate builds but median confidence too low
        fsm.update("trend=flat|vol=high_vol", confidence=0.60)
        fsm.update("trend=flat|vol=high_vol", confidence=0.60)
        fsm.update("trend=flat|vol=high_vol", confidence=0.60)

        # Still on original regime (median 0.60 < 0.75)
        assert fsm.get_state().stable_regime_key == "trend=uptrend|vol=high_vol"

    def test_different_candidate_resets_count(self):
        """Switching to different candidate resets the count."""
        fsm = RegimeFSM(config=FSMConfig(M=5, C_enter=0.70, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        # Build candidate A
        fsm.update("trend=flat|vol=high_vol", confidence=0.75)
        fsm.update("trend=flat|vol=high_vol", confidence=0.75)
        assert fsm.get_state().candidate_count == 2

        # Switch to candidate B
        fsm.update("trend=downtrend|vol=high_vol", confidence=0.75)
        assert fsm.get_state().candidate_count == 1
        assert fsm.get_state().candidate_regime_key == "trend=downtrend|vol=high_vol"


class TestFSMRegimeAge:
    """Tests for regime age tracking."""

    def test_age_increments_on_same_regime(self):
        """Age increments each bar while in same stable regime."""
        fsm = RegimeFSM(config=FSMConfig(M=20))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        for i in range(5):
            fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)

        assert fsm.get_state().regime_age_bars == 6  # 1 initial + 5 updates

    def test_age_resets_on_transition(self):
        """Age resets to 1 after regime transition."""
        fsm = RegimeFSM(config=FSMConfig(M=2, C_enter=0.70, C_exit=0.55))
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)
        fsm.update("trend=uptrend|vol=high_vol", confidence=0.8)
        assert fsm.get_state().regime_age_bars == 3

        # Transition
        fsm.update("trend=flat|vol=high_vol", confidence=0.8)
        fsm.update("trend=flat|vol=high_vol", confidence=0.8)

        assert fsm.get_state().regime_age_bars == 1  # Reset after transition
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_regime_fsm.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write minimal implementation**

```python
# app/services/kb/regime_fsm.py
"""
Regime stability FSM with hysteresis guard.

Prevents slice spam from regime flicker by requiring:
1. M consecutive bars of candidate regime
2. Median confidence >= C_enter over those M bars
3. Confidence >= C_exit to even consider a change (hysteresis)
"""

from dataclasses import dataclass, field
from statistics import median
from typing import Optional


@dataclass
class FSMConfig:
    """FSM configuration (per workspace+timeframe)."""
    M: int = 20  # Persistence bars required
    C_enter: float = 0.75  # Confidence threshold to confirm transition
    C_exit: float = 0.55  # Confidence threshold to consider change


@dataclass
class FSMState:
    """Current FSM state (exposed via API)."""
    stable_regime_key: Optional[str] = None
    candidate_regime_key: Optional[str] = None
    candidate_count: int = 0
    regime_age_bars: int = 0
    config: FSMConfig = field(default_factory=FSMConfig)


@dataclass
class RegimeTransitionEvent:
    """Event emitted when stable regime changes."""
    from_key: str
    to_key: str
    confidence_median: float
    bars_persisted: int


class RegimeFSM:
    """
    Finite state machine for regime stability tracking.

    Implements hysteresis to prevent flicker-induced transitions.
    """

    def __init__(self, config: Optional[FSMConfig] = None):
        self._config = config or FSMConfig()
        self._stable_regime_key: Optional[str] = None
        self._candidate_regime_key: Optional[str] = None
        self._candidate_count: int = 0
        self._confidence_buffer: list[float] = []
        self._regime_age_bars: int = 0

    def update(
        self,
        raw_regime_key: str,
        confidence: float,
    ) -> Optional[RegimeTransitionEvent]:
        """
        Process a new regime observation.

        Args:
            raw_regime_key: Current regime key from classifier
            confidence: Regime fit confidence (0-1)

        Returns:
            RegimeTransitionEvent if transition confirmed, else None
        """
        # First observation initializes stable regime
        if self._stable_regime_key is None:
            self._stable_regime_key = raw_regime_key
            self._regime_age_bars = 1
            return None

        # Same as stable regime - clear candidate, increment age
        if raw_regime_key == self._stable_regime_key:
            self._candidate_regime_key = None
            self._candidate_count = 0
            self._confidence_buffer.clear()
            self._regime_age_bars += 1
            return None

        # Below C_exit - ignore as noise
        if confidence < self._config.C_exit:
            self._regime_age_bars += 1
            return None

        # Different from stable and above C_exit - build candidate
        if raw_regime_key != self._candidate_regime_key:
            # New candidate
            self._candidate_regime_key = raw_regime_key
            self._candidate_count = 1
            self._confidence_buffer = [confidence]
        else:
            # Same candidate - increment
            self._candidate_count += 1
            self._confidence_buffer.append(confidence)

        # Check for transition confirmation
        if self._candidate_count >= self._config.M:
            recent_confidences = self._confidence_buffer[-self._config.M:]
            median_conf = median(recent_confidences)

            if median_conf >= self._config.C_enter:
                # Confirmed transition
                event = RegimeTransitionEvent(
                    from_key=self._stable_regime_key,
                    to_key=self._candidate_regime_key,
                    confidence_median=median_conf,
                    bars_persisted=self._candidate_count,
                )

                self._stable_regime_key = self._candidate_regime_key
                self._candidate_regime_key = None
                self._candidate_count = 0
                self._confidence_buffer.clear()
                self._regime_age_bars = 1

                return event

        self._regime_age_bars += 1
        return None

    def get_state(self) -> FSMState:
        """Get current FSM state for API exposure."""
        return FSMState(
            stable_regime_key=self._stable_regime_key,
            candidate_regime_key=self._candidate_regime_key,
            candidate_count=self._candidate_count,
            regime_age_bars=self._regime_age_bars,
            config=self._config,
        )

    def reset(self) -> None:
        """Reset FSM to initial state."""
        self._stable_regime_key = None
        self._candidate_regime_key = None
        self._candidate_count = 0
        self._confidence_buffer.clear()
        self._regime_age_bars = 0
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/unit/test_regime_fsm.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/services/kb/regime_fsm.py tests/unit/test_regime_fsm.py
git commit -m "feat(kb): add hysteresis FSM for regime stability"
```

---

### Task 2.3: Distance Z-Score Computation

**Files:**
- Create: `app/services/kb/distance.py`
- Test: `tests/unit/test_distance_z.py`

**Step 1: Write failing tests**

```python
# tests/unit/test_distance_z.py
"""Tests for regime distance z-score computation."""

import pytest
import numpy as np
from app.services.kb.distance import (
    compute_standardized_distance,
    compute_distance_distribution,
    compute_regime_distance_z,
    DistanceResult,
)


class TestStandardizedDistance:
    """Tests for standardized Euclidean distance."""

    def test_identical_vectors_zero_distance(self):
        """Identical vectors have zero distance."""
        x = {"atr_pct": 0.02, "rsi": 50.0, "zscore": 0.0}
        y = {"atr_pct": 0.02, "rsi": 50.0, "zscore": 0.0}
        var = {"atr_pct": 0.0001, "rsi": 100.0, "zscore": 1.0}

        d = compute_standardized_distance(x, y, var)
        assert d == pytest.approx(0.0, abs=1e-9)

    def test_distance_is_scale_free(self):
        """Distance is normalized by variance (scale-free)."""
        x = {"a": 0.0, "b": 0.0}
        y = {"a": 1.0, "b": 10.0}

        # With equal variances, b contributes more
        var_equal = {"a": 1.0, "b": 1.0}
        d_equal = compute_standardized_distance(x, y, var_equal)

        # With scaled variances, contributions equal
        var_scaled = {"a": 1.0, "b": 100.0}
        d_scaled = compute_standardized_distance(x, y, var_scaled)

        assert d_equal > d_scaled

    def test_missing_feature_uses_epsilon(self):
        """Missing variance uses epsilon to avoid div-by-zero."""
        x = {"a": 0.0}
        y = {"a": 1.0}
        var = {}  # No variance info

        d = compute_standardized_distance(x, y, var)
        assert d > 0  # Should not raise


class TestDistanceDistribution:
    """Tests for neighbor distance distribution."""

    def test_robust_median_mad(self):
        """Distribution uses median and MAD (robust to outliers)."""
        distances = [1.0, 1.1, 1.2, 1.0, 100.0]  # One outlier

        result = compute_distance_distribution(distances)

        # Median should be ~1.1, not skewed by outlier
        assert result.mu == pytest.approx(1.1, abs=0.1)
        # Sigma should be small (MAD-based)
        assert result.sigma < 1.0

    def test_single_distance_returns_defaults(self):
        """Single distance returns zero sigma."""
        distances = [1.5]
        result = compute_distance_distribution(distances)

        assert result.mu == 1.5
        assert result.sigma == pytest.approx(0.0, abs=1e-9)


class TestRegimeDistanceZ:
    """Tests for full distance z-score computation."""

    def test_z_score_interpretation(self):
        """Z-score reflects deviation from neighborhood."""
        # Current features match neighborhood well
        current = {"atr_pct": 0.02, "rsi": 50.0}
        neighbors = [
            {"atr_pct": 0.021, "rsi": 51.0},
            {"atr_pct": 0.019, "rsi": 49.0},
            {"atr_pct": 0.020, "rsi": 50.0},
        ]
        cluster_var = {"atr_pct": 0.0001, "rsi": 100.0}

        result = compute_regime_distance_z(current, neighbors, cluster_var)

        # Should be close to 0 (within neighborhood)
        assert abs(result.z_score) < 1.0
        assert result.baseline == "composite"

    def test_outlier_has_high_z(self):
        """Outlier features have high z-score."""
        current = {"atr_pct": 0.10, "rsi": 90.0}  # Very different
        neighbors = [
            {"atr_pct": 0.02, "rsi": 50.0},
            {"atr_pct": 0.02, "rsi": 50.0},
            {"atr_pct": 0.02, "rsi": 50.0},
        ]
        cluster_var = {"atr_pct": 0.0001, "rsi": 100.0}

        result = compute_regime_distance_z(current, neighbors, cluster_var)

        # Should have high z-score
        assert result.z_score > 2.0

    def test_shrinkage_blends_prior_and_observed(self):
        """Shrinkage parameter blends cluster prior with observed."""
        current = {"a": 0.5}
        neighbors = [{"a": 0.5}, {"a": 0.5}]  # K=2
        cluster_var = {"a": 1.0}

        result_low_k = compute_regime_distance_z(
            current, neighbors, cluster_var, shrinkage_c=10
        )

        # With more neighbors, less reliance on prior
        neighbors_many = [{"a": 0.5}] * 100
        result_high_k = compute_regime_distance_z(
            current, neighbors_many, cluster_var, shrinkage_c=10
        )

        # Both should work without error
        assert result_low_k.n_neighbors == 2
        assert result_high_k.n_neighbors == 100

    def test_empty_neighbors_returns_missing(self):
        """Empty neighbors returns null z-score with missing reason."""
        current = {"a": 0.5}
        neighbors = []
        cluster_var = {"a": 1.0}

        result = compute_regime_distance_z(current, neighbors, cluster_var)

        assert result.z_score is None
        assert "no_neighbors" in result.missing

    def test_fallback_to_neighbors_only(self):
        """When no cluster variance, uses neighbors-only baseline."""
        current = {"a": 0.5}
        neighbors = [{"a": 0.4}, {"a": 0.6}, {"a": 0.5}]
        cluster_var = None  # No cluster stats available

        result = compute_regime_distance_z(current, neighbors, cluster_var)

        assert result.z_score is not None
        assert result.baseline == "neighbors_only"
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_distance_z.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write minimal implementation**

```python
# app/services/kb/distance.py
"""
Regime distance z-score computation.

Measures how far current features are from the retrieved neighborhood,
normalized by cluster statistics (for scaling) and neighbor distribution
(for baseline).
"""

import math
from dataclasses import dataclass, field
from typing import Optional

# Epsilon to prevent division by zero
EPSILON = 1e-9

# Default shrinkage parameter (alpha = c / (c + K))
DEFAULT_SHRINKAGE_C = 20


@dataclass
class DistributionStats:
    """Robust distribution statistics."""
    mu: float
    sigma: float


@dataclass
class DistanceResult:
    """Result of distance z-score computation."""
    z_score: Optional[float]
    distance_now: Optional[float] = None
    mu: Optional[float] = None
    sigma: Optional[float] = None
    baseline: str = "composite"  # composite | marginal | neighbors_only
    n_neighbors: int = 0
    missing: list[str] = field(default_factory=list)


def compute_standardized_distance(
    x: dict[str, float],
    y: dict[str, float],
    var: Optional[dict[str, float]],
    epsilon: float = EPSILON,
) -> float:
    """
    Compute standardized Euclidean distance (diagonal Mahalanobis).

    d(x, y) = sqrt(sum_i ((x_i - y_i)^2 / (sigma_i^2 + epsilon)))

    Args:
        x: Feature vector (dict of feature_name -> value)
        y: Feature vector
        var: Diagonal variances (dict of feature_name -> variance)
        epsilon: Small value to prevent div-by-zero

    Returns:
        Standardized distance
    """
    if var is None:
        var = {}

    # Use intersection of features
    common_features = set(x.keys()) & set(y.keys())
    if not common_features:
        return 0.0

    sum_sq = 0.0
    for feat in common_features:
        diff = x[feat] - y[feat]
        variance = var.get(feat, epsilon) + epsilon
        sum_sq += (diff ** 2) / variance

    return math.sqrt(sum_sq)


def compute_distance_distribution(distances: list[float]) -> DistributionStats:
    """
    Compute robust distribution stats from distances.

    Uses median and MAD (median absolute deviation) for robustness.

    Args:
        distances: List of distance values

    Returns:
        DistributionStats with mu (median) and sigma (1.4826 * MAD)
    """
    if not distances:
        return DistributionStats(mu=0.0, sigma=EPSILON)

    if len(distances) == 1:
        return DistributionStats(mu=distances[0], sigma=0.0)

    sorted_d = sorted(distances)
    n = len(sorted_d)

    # Median
    if n % 2 == 0:
        mu = (sorted_d[n // 2 - 1] + sorted_d[n // 2]) / 2
    else:
        mu = sorted_d[n // 2]

    # MAD (median absolute deviation)
    abs_devs = sorted([abs(d - mu) for d in distances])
    if len(abs_devs) % 2 == 0:
        mad = (abs_devs[len(abs_devs) // 2 - 1] + abs_devs[len(abs_devs) // 2]) / 2
    else:
        mad = abs_devs[len(abs_devs) // 2]

    # Convert MAD to std estimate: sigma = 1.4826 * MAD
    sigma = 1.4826 * mad

    return DistributionStats(mu=mu, sigma=sigma)


def compute_regime_distance_z(
    current_features: dict[str, float],
    neighbor_features: list[dict[str, float]],
    cluster_var: Optional[dict[str, float]],
    cluster_sigma_prior: Optional[float] = None,
    shrinkage_c: float = DEFAULT_SHRINKAGE_C,
) -> DistanceResult:
    """
    Compute regime distance z-score.

    Algorithm:
    1. Compute distances from current to each neighbor (using cluster var for scaling)
    2. Build neighbor distance distribution (mu, sigma_obs)
    3. Apply shrinkage to blend cluster prior with observed
    4. Compute z-score

    Args:
        current_features: Current regime feature vector
        neighbor_features: List of neighbor feature vectors from retrieval
        cluster_var: Diagonal variances from cluster stats (for scaling)
        cluster_sigma_prior: Prior sigma from cluster stats (optional)
        shrinkage_c: Shrinkage parameter (alpha = c / (c + K))

    Returns:
        DistanceResult with z_score, baseline info, and missing reasons
    """
    missing = []

    if not neighbor_features:
        return DistanceResult(
            z_score=None,
            baseline="none",
            n_neighbors=0,
            missing=["no_neighbors"],
        )

    # Determine baseline type
    if cluster_var is not None and len(cluster_var) > 0:
        baseline = "composite"
    else:
        baseline = "neighbors_only"
        cluster_var = {}  # Will use epsilon for all

    # Step 1: Compute distances to all neighbors
    distances = []
    for neighbor in neighbor_features:
        d = compute_standardized_distance(
            current_features, neighbor, cluster_var
        )
        distances.append(d)

    # Step 2: Build neighbor distance distribution
    dist_stats = compute_distance_distribution(distances)
    mu = dist_stats.mu
    sigma_obs = dist_stats.sigma

    # Step 3: Apply shrinkage
    K = len(neighbor_features)
    alpha = shrinkage_c / (shrinkage_c + K)

    if cluster_sigma_prior is not None:
        sigma = alpha * cluster_sigma_prior + (1 - alpha) * sigma_obs
    else:
        sigma = sigma_obs

    # Step 4: Compute z-score
    # d_now = median distance to neighbors (same as mu)
    d_now = mu

    if sigma < EPSILON:
        # All neighbors at same distance, z=0
        z_score = 0.0
    else:
        z_score = (d_now - mu) / (sigma + EPSILON)

    return DistanceResult(
        z_score=z_score,
        distance_now=d_now,
        mu=mu,
        sigma=sigma,
        baseline=baseline,
        n_neighbors=K,
        missing=missing,
    )
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/unit/test_distance_z.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/services/kb/distance.py tests/unit/test_distance_z.py
git commit -m "feat(kb): add regime distance z-score computation"
```

---

## Phase 3: Repository Layer

### Task 3.1: Cluster Stats Repository

**Files:**
- Create: `app/repositories/cluster_stats.py`
- Test: `tests/unit/test_cluster_stats_repo.py`

**Step 1: Write failing tests**

```python
# tests/unit/test_cluster_stats_repo.py
"""Tests for cluster stats repository."""

import pytest
from uuid import uuid4
from unittest.mock import AsyncMock, MagicMock

from app.repositories.cluster_stats import (
    ClusterStatsRepository,
    ClusterStats,
)


@pytest.fixture
def mock_pool():
    """Create mock database pool."""
    pool = MagicMock()
    pool.acquire = MagicMock(return_value=AsyncMock())
    return pool


class TestClusterStatsRepository:
    """Tests for ClusterStatsRepository."""

    @pytest.mark.asyncio
    async def test_get_stats_returns_none_when_missing(self, mock_pool):
        """Returns None when no stats exist for key."""
        repo = ClusterStatsRepository(mock_pool)

        # Mock empty result
        conn = AsyncMock()
        conn.fetchrow = AsyncMock(return_value=None)
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_stats(
            strategy_entity_id=uuid4(),
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
        )

        assert result is None

    @pytest.mark.asyncio
    async def test_get_stats_with_backoff(self, mock_pool):
        """Falls back to marginal when composite missing."""
        repo = ClusterStatsRepository(mock_pool)

        call_count = 0
        async def mock_fetchrow(query, *args):
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                # Composite not found
                return None
            else:
                # Marginal found
                return {
                    "n": 10,
                    "feature_mean": {"atr_pct": 0.02},
                    "feature_var": {"atr_pct": 0.001},
                    "regime_key": "trend=uptrend",
                }

        conn = AsyncMock()
        conn.fetchrow = mock_fetchrow
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_stats_with_backoff(
            strategy_entity_id=uuid4(),
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
        )

        assert result is not None
        assert result.baseline == "marginal"

    @pytest.mark.asyncio
    async def test_upsert_stats(self, mock_pool):
        """Upsert creates or updates stats."""
        repo = ClusterStatsRepository(mock_pool)

        conn = AsyncMock()
        conn.execute = AsyncMock()
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        stats = ClusterStats(
            strategy_entity_id=uuid4(),
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
            regime_dims={"trend": "uptrend", "vol": "high_vol"},
            n=50,
            feature_mean={"atr_pct": 0.02, "rsi": 50.0},
            feature_var={"atr_pct": 0.001, "rsi": 100.0},
        )

        await repo.upsert_stats(stats)

        conn.execute.assert_called_once()
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_cluster_stats_repo.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write minimal implementation**

```python
# app/repositories/cluster_stats.py
"""
Repository for regime cluster statistics.

Provides CRUD operations and backoff queries for cluster stats.
"""

import json
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
from uuid import UUID

from app.services.kb.regime_key import extract_marginal_keys


@dataclass
class ClusterStats:
    """Cluster statistics for a regime key."""
    strategy_entity_id: UUID
    timeframe: str
    regime_key: str
    regime_dims: dict
    n: int
    feature_mean: dict[str, float]
    feature_var: dict[str, float]
    feature_min: Optional[dict[str, float]] = None
    feature_max: Optional[dict[str, float]] = None
    feature_schema_version: int = 1
    updated_at: Optional[datetime] = None
    baseline: str = "composite"  # composite | marginal | neighbors_only


class ClusterStatsRepository:
    """Repository for regime_cluster_stats table."""

    def __init__(self, pool):
        """
        Initialize repository.

        Args:
            pool: asyncpg connection pool
        """
        self._pool = pool

    async def get_stats(
        self,
        strategy_entity_id: UUID,
        timeframe: str,
        regime_key: str,
    ) -> Optional[ClusterStats]:
        """
        Get cluster stats for exact regime key.

        Args:
            strategy_entity_id: Strategy entity ID
            timeframe: Timeframe string
            regime_key: Canonical regime key

        Returns:
            ClusterStats or None if not found
        """
        query = """
            SELECT
                strategy_entity_id, timeframe, regime_key, regime_dims,
                n, feature_schema_version, feature_mean, feature_var,
                feature_min, feature_max, updated_at
            FROM regime_cluster_stats
            WHERE strategy_entity_id = $1
              AND timeframe = $2
              AND regime_key = $3
        """

        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(query, strategy_entity_id, timeframe, regime_key)

        if row is None:
            return None

        return self._row_to_stats(row, baseline="composite")

    async def get_stats_with_backoff(
        self,
        strategy_entity_id: UUID,
        timeframe: str,
        regime_key: str,
        min_n: int = 20,
    ) -> Optional[ClusterStats]:
        """
        Get cluster stats with backoff chain.

        Backoff order:
        1. Exact composite key
        2. Marginal keys (max variance per feature)
        3. None

        Args:
            strategy_entity_id: Strategy entity ID
            timeframe: Timeframe string
            regime_key: Canonical regime key
            min_n: Minimum sample count to accept

        Returns:
            ClusterStats with baseline indicator, or None
        """
        # Try exact composite first
        stats = await self.get_stats(strategy_entity_id, timeframe, regime_key)
        if stats is not None and stats.n >= min_n:
            return stats

        # Try marginals
        marginal_keys = extract_marginal_keys(regime_key)
        marginal_stats = []

        for marginal in marginal_keys:
            ms = await self.get_stats(strategy_entity_id, timeframe, marginal)
            if ms is not None:
                marginal_stats.append(ms)

        if marginal_stats:
            # Combine marginals: take max variance per feature for safety
            combined = self._combine_marginals(marginal_stats)
            combined.baseline = "marginal"
            return combined

        return None

    async def upsert_stats(self, stats: ClusterStats) -> None:
        """
        Insert or update cluster stats.

        Args:
            stats: ClusterStats to upsert
        """
        query = """
            INSERT INTO regime_cluster_stats (
                strategy_entity_id, timeframe, regime_key, regime_dims,
                n, feature_schema_version, feature_mean, feature_var,
                feature_min, feature_max, updated_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, now())
            ON CONFLICT (strategy_entity_id, timeframe, regime_key)
            DO UPDATE SET
                regime_dims = EXCLUDED.regime_dims,
                n = EXCLUDED.n,
                feature_schema_version = EXCLUDED.feature_schema_version,
                feature_mean = EXCLUDED.feature_mean,
                feature_var = EXCLUDED.feature_var,
                feature_min = EXCLUDED.feature_min,
                feature_max = EXCLUDED.feature_max,
                updated_at = now()
        """

        async with self._pool.acquire() as conn:
            await conn.execute(
                query,
                stats.strategy_entity_id,
                stats.timeframe,
                stats.regime_key,
                json.dumps(stats.regime_dims),
                stats.n,
                stats.feature_schema_version,
                json.dumps(stats.feature_mean),
                json.dumps(stats.feature_var),
                json.dumps(stats.feature_min) if stats.feature_min else None,
                json.dumps(stats.feature_max) if stats.feature_max else None,
            )

    def _row_to_stats(self, row: dict, baseline: str = "composite") -> ClusterStats:
        """Convert database row to ClusterStats."""
        return ClusterStats(
            strategy_entity_id=row["strategy_entity_id"],
            timeframe=row["timeframe"],
            regime_key=row["regime_key"],
            regime_dims=row["regime_dims"] if isinstance(row["regime_dims"], dict) else json.loads(row["regime_dims"]),
            n=row["n"],
            feature_schema_version=row.get("feature_schema_version", 1),
            feature_mean=row["feature_mean"] if isinstance(row["feature_mean"], dict) else json.loads(row["feature_mean"]),
            feature_var=row["feature_var"] if isinstance(row["feature_var"], dict) else json.loads(row["feature_var"]),
            feature_min=row.get("feature_min"),
            feature_max=row.get("feature_max"),
            updated_at=row.get("updated_at"),
            baseline=baseline,
        )

    def _combine_marginals(self, marginals: list[ClusterStats]) -> ClusterStats:
        """
        Combine marginal stats conservatively.

        Takes max variance per feature to avoid underestimating spread.
        """
        if len(marginals) == 1:
            return marginals[0]

        # Combine means (average)
        all_features = set()
        for m in marginals:
            all_features.update(m.feature_mean.keys())

        combined_mean = {}
        combined_var = {}

        for feat in all_features:
            means = [m.feature_mean.get(feat) for m in marginals if feat in m.feature_mean]
            vars_ = [m.feature_var.get(feat) for m in marginals if feat in m.feature_var]

            if means:
                combined_mean[feat] = sum(means) / len(means)
            if vars_:
                combined_var[feat] = max(vars_)  # Conservative: max variance

        total_n = sum(m.n for m in marginals)

        return ClusterStats(
            strategy_entity_id=marginals[0].strategy_entity_id,
            timeframe=marginals[0].timeframe,
            regime_key=marginals[0].regime_key,
            regime_dims=marginals[0].regime_dims,
            n=total_n,
            feature_mean=combined_mean,
            feature_var=combined_var,
            baseline="marginal",
        )
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/unit/test_cluster_stats_repo.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/repositories/cluster_stats.py tests/unit/test_cluster_stats_repo.py
git commit -m "feat(repo): add cluster stats repository with backoff"
```

---

### Task 3.2: Duration Stats Repository

**Files:**
- Create: `app/repositories/duration_stats.py`
- Test: `tests/unit/test_duration_stats_repo.py`

**Step 1: Write failing tests**

```python
# tests/unit/test_duration_stats_repo.py
"""Tests for duration stats repository."""

import pytest
from unittest.mock import AsyncMock, MagicMock

from app.repositories.duration_stats import (
    DurationStatsRepository,
    DurationStats,
)


@pytest.fixture
def mock_pool():
    """Create mock database pool."""
    pool = MagicMock()
    pool.acquire = MagicMock(return_value=AsyncMock())
    return pool


class TestDurationStatsRepository:
    """Tests for DurationStatsRepository."""

    @pytest.mark.asyncio
    async def test_get_stats_returns_none_when_missing(self, mock_pool):
        """Returns None when no stats exist."""
        repo = DurationStatsRepository(mock_pool)

        conn = AsyncMock()
        conn.fetchrow = AsyncMock(return_value=None)
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_stats(
            symbol="BTC/USDT",
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
        )

        assert result is None

    @pytest.mark.asyncio
    async def test_get_stats_with_backoff_tries_marginals(self, mock_pool):
        """Backoff tries marginal keys when composite missing."""
        repo = DurationStatsRepository(mock_pool)

        call_count = 0
        async def mock_fetchrow(query, *args):
            nonlocal call_count
            call_count += 1
            if call_count <= 2:  # Composite and first marginal
                return None
            else:
                # Second marginal found
                return {
                    "symbol": "BTC/USDT",
                    "timeframe": "5m",
                    "regime_key": "vol=high_vol",
                    "n_segments": 25,
                    "median_duration_bars": 200,
                    "p25_duration_bars": 100,
                    "p75_duration_bars": 350,
                }

        conn = AsyncMock()
        conn.fetchrow = mock_fetchrow
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_stats_with_backoff(
            symbol="BTC/USDT",
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
        )

        assert result is not None
        assert result.baseline == "marginal"
        assert result.median_duration_bars == 200

    @pytest.mark.asyncio
    async def test_expected_remaining_computed(self, mock_pool):
        """Expected remaining is computed from median - age."""
        repo = DurationStatsRepository(mock_pool)

        conn = AsyncMock()
        conn.fetchrow = AsyncMock(return_value={
            "symbol": "BTC/USDT",
            "timeframe": "5m",
            "regime_key": "trend=uptrend|vol=high_vol",
            "n_segments": 50,
            "median_duration_bars": 240,
            "p25_duration_bars": 180,
            "p75_duration_bars": 310,
        })
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_stats(
            symbol="BTC/USDT",
            timeframe="5m",
            regime_key="trend=uptrend|vol=high_vol",
        )

        # Compute expected remaining for age=120
        remaining = result.compute_expected_remaining(regime_age_bars=120)
        assert remaining.expected_remaining_bars == 120  # 240 - 120
        assert remaining.remaining_iqr_bars == [60, 190]  # [180-120, 310-120]
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_duration_stats_repo.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write minimal implementation**

```python
# app/repositories/duration_stats.py
"""
Repository for regime duration statistics.

Provides CRUD operations and backoff queries for duration stats.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional

from app.services.kb.regime_key import extract_marginal_keys


@dataclass
class RemainingEstimate:
    """Estimated remaining duration."""
    expected_remaining_bars: int
    remaining_iqr_bars: list[int]  # [p25_remaining, p75_remaining]


@dataclass
class DurationStats:
    """Duration statistics for a regime key."""
    symbol: str
    timeframe: str
    regime_key: str
    n_segments: int
    median_duration_bars: int
    p25_duration_bars: int
    p75_duration_bars: int
    updated_at: Optional[datetime] = None
    baseline: str = "composite_symbol"  # composite_symbol | marginal | global_timeframe

    def compute_expected_remaining(self, regime_age_bars: int) -> RemainingEstimate:
        """
        Compute expected remaining duration.

        Args:
            regime_age_bars: Current regime age in bars

        Returns:
            RemainingEstimate with expected remaining and IQR
        """
        expected = max(0, self.median_duration_bars - regime_age_bars)
        p25_remaining = max(0, self.p25_duration_bars - regime_age_bars)
        p75_remaining = max(0, self.p75_duration_bars - regime_age_bars)

        return RemainingEstimate(
            expected_remaining_bars=expected,
            remaining_iqr_bars=[p25_remaining, p75_remaining],
        )

    @property
    def duration_iqr_bars(self) -> list[int]:
        """Get duration IQR as list."""
        return [self.p25_duration_bars, self.p75_duration_bars]


class DurationStatsRepository:
    """Repository for regime_duration_stats table."""

    def __init__(self, pool):
        """
        Initialize repository.

        Args:
            pool: asyncpg connection pool
        """
        self._pool = pool

    async def get_stats(
        self,
        symbol: str,
        timeframe: str,
        regime_key: str,
    ) -> Optional[DurationStats]:
        """
        Get duration stats for exact regime key.

        Args:
            symbol: Trading symbol
            timeframe: Timeframe string
            regime_key: Canonical regime key

        Returns:
            DurationStats or None if not found
        """
        query = """
            SELECT
                symbol, timeframe, regime_key,
                n_segments, median_duration_bars,
                p25_duration_bars, p75_duration_bars,
                updated_at
            FROM regime_duration_stats
            WHERE symbol = $1
              AND timeframe = $2
              AND regime_key = $3
        """

        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(query, symbol, timeframe, regime_key)

        if row is None:
            return None

        return self._row_to_stats(row, baseline="composite_symbol")

    async def get_stats_with_backoff(
        self,
        symbol: str,
        timeframe: str,
        regime_key: str,
        min_segments: int = 10,
    ) -> Optional[DurationStats]:
        """
        Get duration stats with backoff chain.

        Backoff order:
        1. Exact composite for symbol+timeframe
        2. Marginal keys for symbol+timeframe
        3. Global timeframe (any symbol)
        4. None

        Args:
            symbol: Trading symbol
            timeframe: Timeframe string
            regime_key: Canonical regime key
            min_segments: Minimum segment count to accept

        Returns:
            DurationStats with baseline indicator, or None
        """
        # Try exact composite first
        stats = await self.get_stats(symbol, timeframe, regime_key)
        if stats is not None and stats.n_segments >= min_segments:
            return stats

        # Try marginals for this symbol
        marginal_keys = extract_marginal_keys(regime_key)
        for marginal in marginal_keys:
            ms = await self.get_stats(symbol, timeframe, marginal)
            if ms is not None and ms.n_segments >= min_segments:
                ms.baseline = "marginal"
                return ms

        # Try global timeframe (aggregate across symbols)
        global_stats = await self._get_global_timeframe_stats(timeframe, regime_key)
        if global_stats is not None and global_stats.n_segments >= min_segments:
            global_stats.baseline = "global_timeframe"
            return global_stats

        return None

    async def _get_global_timeframe_stats(
        self,
        timeframe: str,
        regime_key: str,
    ) -> Optional[DurationStats]:
        """Get aggregated stats across all symbols for a timeframe."""
        query = """
            SELECT
                $2 as symbol,
                timeframe,
                regime_key,
                SUM(n_segments) as n_segments,
                PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY median_duration_bars) as median_duration_bars,
                PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY median_duration_bars) as p25_duration_bars,
                PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY median_duration_bars) as p75_duration_bars,
                MAX(updated_at) as updated_at
            FROM regime_duration_stats
            WHERE timeframe = $1
              AND regime_key = $3
            GROUP BY timeframe, regime_key
        """

        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(query, timeframe, "global", regime_key)

        if row is None or row["n_segments"] is None:
            return None

        return self._row_to_stats(row, baseline="global_timeframe")

    async def upsert_stats(self, stats: DurationStats) -> None:
        """
        Insert or update duration stats.

        Args:
            stats: DurationStats to upsert
        """
        query = """
            INSERT INTO regime_duration_stats (
                symbol, timeframe, regime_key,
                n_segments, median_duration_bars,
                p25_duration_bars, p75_duration_bars,
                updated_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, now())
            ON CONFLICT (symbol, timeframe, regime_key)
            DO UPDATE SET
                n_segments = EXCLUDED.n_segments,
                median_duration_bars = EXCLUDED.median_duration_bars,
                p25_duration_bars = EXCLUDED.p25_duration_bars,
                p75_duration_bars = EXCLUDED.p75_duration_bars,
                updated_at = now()
        """

        async with self._pool.acquire() as conn:
            await conn.execute(
                query,
                stats.symbol,
                stats.timeframe,
                stats.regime_key,
                stats.n_segments,
                stats.median_duration_bars,
                stats.p25_duration_bars,
                stats.p75_duration_bars,
            )

    def _row_to_stats(self, row: dict, baseline: str) -> DurationStats:
        """Convert database row to DurationStats."""
        return DurationStats(
            symbol=row["symbol"],
            timeframe=row["timeframe"],
            regime_key=row["regime_key"],
            n_segments=int(row["n_segments"]),
            median_duration_bars=int(row["median_duration_bars"]),
            p25_duration_bars=int(row["p25_duration_bars"]),
            p75_duration_bars=int(row["p75_duration_bars"]),
            updated_at=row.get("updated_at"),
            baseline=baseline,
        )
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/unit/test_duration_stats_repo.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/repositories/duration_stats.py tests/unit/test_duration_stats_repo.py
git commit -m "feat(repo): add duration stats repository with backoff"
```

---

### Task 3.3: Recommendation Records Repository

**Files:**
- Create: `app/repositories/recommendation_records.py`
- Test: `tests/unit/test_recommendation_records_repo.py`

**Step 1: Write failing tests**

```python
# tests/unit/test_recommendation_records_repo.py
"""Tests for recommendation records repository."""

import pytest
from uuid import uuid4
from datetime import datetime, timezone
from unittest.mock import AsyncMock, MagicMock

from app.repositories.recommendation_records import (
    RecommendationRecordsRepository,
    RecommendationRecord,
    RecordStatus,
)


@pytest.fixture
def mock_pool():
    """Create mock database pool."""
    pool = MagicMock()
    pool.acquire = MagicMock(return_value=AsyncMock())
    return pool


class TestRecommendationRecordsRepository:
    """Tests for RecommendationRecordsRepository."""

    @pytest.mark.asyncio
    async def test_create_record_supersedes_existing(self, mock_pool):
        """Creating a new record supersedes the existing active one."""
        repo = RecommendationRecordsRepository(mock_pool)

        executed_queries = []
        async def mock_execute(query, *args):
            executed_queries.append(query)

        conn = AsyncMock()
        conn.execute = mock_execute
        conn.fetchrow = AsyncMock(return_value={"id": uuid4()})
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        record = RecommendationRecord(
            workspace_id=uuid4(),
            strategy_entity_id=uuid4(),
            symbol="BTC/USDT",
            timeframe="5m",
            params_json={"period": 14},
            params_hash="abc123",
            regime_key_start="trend=uptrend|vol=high_vol",
            regime_dims_start={"trend": "uptrend", "vol": "high_vol"},
            regime_features_start={"atr_pct": 0.02},
            confidence_json={"regime_fit_confidence": 0.8},
            expected_baselines_json={"sharpe_mean": 1.2},
        )

        await repo.create_record(record)

        # Should have UPDATE to supersede existing + INSERT new
        assert any("UPDATE" in q and "superseded" in q for q in executed_queries)

    @pytest.mark.asyncio
    async def test_get_active_record(self, mock_pool):
        """Gets the active record for symbol+strategy."""
        repo = RecommendationRecordsRepository(mock_pool)

        record_id = uuid4()
        conn = AsyncMock()
        conn.fetchrow = AsyncMock(return_value={
            "id": record_id,
            "workspace_id": uuid4(),
            "strategy_entity_id": uuid4(),
            "symbol": "BTC/USDT",
            "timeframe": "5m",
            "params_json": {"period": 14},
            "params_hash": "abc123",
            "regime_key_start": "trend=uptrend|vol=high_vol",
            "regime_dims_start": {"trend": "uptrend", "vol": "high_vol"},
            "regime_features_start": {"atr_pct": 0.02},
            "confidence_json": {"regime_fit_confidence": 0.8},
            "expected_baselines_json": {"sharpe_mean": 1.2},
            "status": "active",
            "schema_version": 1,
            "created_at": datetime.now(timezone.utc),
            "updated_at": datetime.now(timezone.utc),
        })
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        result = await repo.get_active_record(
            workspace_id=uuid4(),
            strategy_entity_id=uuid4(),
            symbol="BTC/USDT",
            timeframe="5m",
        )

        assert result is not None
        assert result.status == RecordStatus.ACTIVE

    @pytest.mark.asyncio
    async def test_close_record(self, mock_pool):
        """Closing record updates status."""
        repo = RecommendationRecordsRepository(mock_pool)

        conn = AsyncMock()
        conn.execute = AsyncMock()
        mock_pool.acquire.return_value.__aenter__ = AsyncMock(return_value=conn)
        mock_pool.acquire.return_value.__aexit__ = AsyncMock()

        await repo.close_record(
            record_id=uuid4(),
            new_status=RecordStatus.CLOSED,
        )

        conn.execute.assert_called_once()
        call_args = conn.execute.call_args
        assert "closed" in str(call_args)
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/unit/test_recommendation_records_repo.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write implementation** (abbreviated for length)

```python
# app/repositories/recommendation_records.py
"""
Repository for recommendation records and related entities.

Handles CRUD for recommendation_records, recommendation_observations,
and recommendation_evaluation_slices tables.
"""

import json
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Optional
from uuid import UUID


class RecordStatus(str, Enum):
    """Recommendation record status."""
    ACTIVE = "active"
    SUPERSEDED = "superseded"
    INACTIVE = "inactive"
    CLOSED = "closed"


@dataclass
class RecommendationRecord:
    """Recommendation expectation contract."""
    workspace_id: UUID
    strategy_entity_id: UUID
    symbol: str
    timeframe: str
    params_json: dict
    params_hash: str
    regime_key_start: str
    regime_dims_start: dict
    regime_features_start: dict
    confidence_json: dict
    expected_baselines_json: dict
    id: Optional[UUID] = None
    status: RecordStatus = RecordStatus.ACTIVE
    schema_version: int = 1
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None


@dataclass
class RecommendationObservation:
    """Streaming realized metrics observation."""
    record_id: UUID
    ts: datetime
    bars_seen: int
    trades_seen: int
    realized_metrics_json: dict
    id: Optional[UUID] = None
    created_at: Optional[datetime] = None


@dataclass
class EvaluationSlice:
    """Accountability checkpoint."""
    record_id: UUID
    slice_start_ts: datetime
    slice_end_ts: datetime
    trigger_type: str  # regime_change | milestone | manual
    regime_key_during: str
    realized_summary_json: dict
    expected_summary_json: dict
    performance_surprise_z: Optional[float] = None
    drift_flags_json: Optional[dict] = None
    id: Optional[UUID] = None
    created_at: Optional[datetime] = None


class RecommendationRecordsRepository:
    """Repository for recommendation records and related tables."""

    def __init__(self, pool):
        self._pool = pool

    async def create_record(self, record: RecommendationRecord) -> UUID:
        """
        Create new recommendation record, superseding any existing active one.

        Returns:
            ID of created record
        """
        async with self._pool.acquire() as conn:
            # Supersede existing active record
            await conn.execute(
                """
                UPDATE recommendation_records
                SET status = 'superseded', updated_at = now()
                WHERE workspace_id = $1
                  AND strategy_entity_id = $2
                  AND symbol = $3
                  AND timeframe = $4
                  AND status = 'active'
                """,
                record.workspace_id,
                record.strategy_entity_id,
                record.symbol,
                record.timeframe,
            )

            # Insert new record
            row = await conn.fetchrow(
                """
                INSERT INTO recommendation_records (
                    workspace_id, strategy_entity_id, symbol, timeframe,
                    params_json, params_hash,
                    regime_key_start, regime_dims_start, regime_features_start,
                    schema_version, confidence_json, expected_baselines_json,
                    status
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, 'active')
                RETURNING id
                """,
                record.workspace_id,
                record.strategy_entity_id,
                record.symbol,
                record.timeframe,
                json.dumps(record.params_json),
                record.params_hash,
                record.regime_key_start,
                json.dumps(record.regime_dims_start),
                json.dumps(record.regime_features_start),
                record.schema_version,
                json.dumps(record.confidence_json),
                json.dumps(record.expected_baselines_json),
            )

            return row["id"]

    async def get_active_record(
        self,
        workspace_id: UUID,
        strategy_entity_id: UUID,
        symbol: str,
        timeframe: str,
    ) -> Optional[RecommendationRecord]:
        """Get active record for symbol+strategy."""
        query = """
            SELECT * FROM recommendation_records
            WHERE workspace_id = $1
              AND strategy_entity_id = $2
              AND symbol = $3
              AND timeframe = $4
              AND status = 'active'
        """

        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(
                query, workspace_id, strategy_entity_id, symbol, timeframe
            )

        if row is None:
            return None

        return self._row_to_record(row)

    async def close_record(
        self,
        record_id: UUID,
        new_status: RecordStatus,
    ) -> None:
        """Close a record with specified status."""
        async with self._pool.acquire() as conn:
            await conn.execute(
                """
                UPDATE recommendation_records
                SET status = $2, updated_at = now()
                WHERE id = $1
                """,
                record_id,
                new_status.value,
            )

    async def add_observation(self, obs: RecommendationObservation) -> UUID:
        """
        Add observation to record.

        Returns observation ID. Raises on duplicate (record_id, ts).
        """
        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(
                """
                INSERT INTO recommendation_observations (
                    record_id, ts, bars_seen, trades_seen, realized_metrics_json
                ) VALUES ($1, $2, $3, $4, $5)
                RETURNING id
                """,
                obs.record_id,
                obs.ts,
                obs.bars_seen,
                obs.trades_seen,
                json.dumps(obs.realized_metrics_json),
            )
            return row["id"]

    async def create_slice(self, slice_: EvaluationSlice) -> UUID:
        """Create evaluation slice."""
        async with self._pool.acquire() as conn:
            row = await conn.fetchrow(
                """
                INSERT INTO recommendation_evaluation_slices (
                    record_id, slice_start_ts, slice_end_ts,
                    trigger_type, regime_key_during,
                    realized_summary_json, expected_summary_json,
                    performance_surprise_z, drift_flags_json
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                RETURNING id
                """,
                slice_.record_id,
                slice_.slice_start_ts,
                slice_.slice_end_ts,
                slice_.trigger_type,
                slice_.regime_key_during,
                json.dumps(slice_.realized_summary_json),
                json.dumps(slice_.expected_summary_json),
                slice_.performance_surprise_z,
                json.dumps(slice_.drift_flags_json) if slice_.drift_flags_json else None,
            )
            return row["id"]

    def _row_to_record(self, row: dict) -> RecommendationRecord:
        """Convert database row to RecommendationRecord."""
        return RecommendationRecord(
            id=row["id"],
            workspace_id=row["workspace_id"],
            strategy_entity_id=row["strategy_entity_id"],
            symbol=row["symbol"],
            timeframe=row["timeframe"],
            params_json=row["params_json"] if isinstance(row["params_json"], dict) else json.loads(row["params_json"]),
            params_hash=row["params_hash"],
            regime_key_start=row["regime_key_start"],
            regime_dims_start=row["regime_dims_start"] if isinstance(row["regime_dims_start"], dict) else json.loads(row["regime_dims_start"]),
            regime_features_start=row["regime_features_start"] if isinstance(row["regime_features_start"], dict) else json.loads(row["regime_features_start"]),
            confidence_json=row["confidence_json"] if isinstance(row["confidence_json"], dict) else json.loads(row["confidence_json"]),
            expected_baselines_json=row["expected_baselines_json"] if isinstance(row["expected_baselines_json"], dict) else json.loads(row["expected_baselines_json"]),
            status=RecordStatus(row["status"]),
            schema_version=row.get("schema_version", 1),
            created_at=row.get("created_at"),
            updated_at=row.get("updated_at"),
        )
```

**Step 4: Run tests**

Run: `pytest tests/unit/test_recommendation_records_repo.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/repositories/recommendation_records.py tests/unit/test_recommendation_records_repo.py
git commit -m "feat(repo): add recommendation records repository"
```

---

## Phase 4: API Endpoints

### Task 4.1: Forward Metrics Endpoint

**Files:**
- Create: `app/routers/forward_metrics.py`
- Test: `tests/unit/test_forward_metrics_router.py`

**Step 1: Write failing tests**

```python
# tests/unit/test_forward_metrics_router.py
"""Tests for forward metrics endpoint."""

import pytest
from datetime import datetime, timezone
from uuid import uuid4
from unittest.mock import AsyncMock, patch

from fastapi.testclient import TestClient
from fastapi import FastAPI

from app.routers.forward_metrics import router, set_db_pool


@pytest.fixture
def app():
    """Create test FastAPI app."""
    app = FastAPI()
    app.include_router(router)
    return app


@pytest.fixture
def client(app):
    """Create test client."""
    return TestClient(app)


class TestForwardMetricsEndpoint:
    """Tests for POST /forward/metrics."""

    def test_accepts_valid_payload(self, client):
        """Accepts valid metrics payload."""
        with patch("app.routers.forward_metrics._get_repository") as mock_repo:
            mock_instance = AsyncMock()
            mock_instance.get_record_by_id = AsyncMock(return_value=AsyncMock(
                status="active"
            ))
            mock_instance.add_observation = AsyncMock(return_value=uuid4())
            mock_repo.return_value = mock_instance

            response = client.post(
                "/forward/metrics",
                json={
                    "workspace_id": str(uuid4()),
                    "record_id": str(uuid4()),
                    "ts": "2026-01-09T12:00:00Z",
                    "bars_seen": 500,
                    "trades_seen": 42,
                    "realized_metrics": {
                        "return_pct": 0.023,
                        "sharpe_proxy": 1.2,
                    },
                },
            )

            assert response.status_code == 200
            data = response.json()
            assert data["status"] == "accepted"
            assert "observation_id" in data

    def test_rejects_inactive_record(self, client):
        """Returns 404 for inactive record."""
        with patch("app.routers.forward_metrics._get_repository") as mock_repo:
            mock_instance = AsyncMock()
            mock_instance.get_record_by_id = AsyncMock(return_value=AsyncMock(
                status="closed"
            ))
            mock_repo.return_value = mock_instance

            response = client.post(
                "/forward/metrics",
                json={
                    "workspace_id": str(uuid4()),
                    "record_id": str(uuid4()),
                    "ts": "2026-01-09T12:00:00Z",
                    "bars_seen": 500,
                    "trades_seen": 42,
                    "realized_metrics": {},
                },
            )

            assert response.status_code == 404

    def test_rejects_duplicate_observation(self, client):
        """Returns 409 for duplicate (record_id, ts)."""
        with patch("app.routers.forward_metrics._get_repository") as mock_repo:
            from asyncpg.exceptions import UniqueViolationError

            mock_instance = AsyncMock()
            mock_instance.get_record_by_id = AsyncMock(return_value=AsyncMock(
                status="active"
            ))
            mock_instance.add_observation = AsyncMock(
                side_effect=UniqueViolationError("")
            )
            mock_repo.return_value = mock_instance

            response = client.post(
                "/forward/metrics",
                json={
                    "workspace_id": str(uuid4()),
                    "record_id": str(uuid4()),
                    "ts": "2026-01-09T12:00:00Z",
                    "bars_seen": 500,
                    "trades_seen": 42,
                    "realized_metrics": {},
                },
            )

            assert response.status_code == 409
```

**Step 2: Run tests**

Run: `pytest tests/unit/test_forward_metrics_router.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write implementation**

```python
# app/routers/forward_metrics.py
"""
Forward metrics endpoint for v1.5 expected-vs-realized tracking.

Receives streaming realized metrics from forward runs (paper/shadow/live).
"""

from datetime import datetime
from typing import Optional
from uuid import UUID

import structlog
from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel, Field

from app.repositories.recommendation_records import (
    RecommendationRecordsRepository,
    RecommendationObservation,
    RecordStatus,
)

router = APIRouter(prefix="/forward", tags=["forward-metrics"])
logger = structlog.get_logger(__name__)

# Global connection pool (set during app startup)
_db_pool = None


def set_db_pool(pool):
    """Set the database pool for this router."""
    global _db_pool
    _db_pool = pool


def _get_repository() -> RecommendationRecordsRepository:
    """Get repository instance."""
    if _db_pool is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Database connection not available",
        )
    return RecommendationRecordsRepository(_db_pool)


# =============================================================================
# Request/Response Schemas
# =============================================================================


class ForwardMetricsRequest(BaseModel):
    """Request to submit forward metrics."""
    workspace_id: UUID
    record_id: UUID
    ts: datetime
    bars_seen: int = Field(..., ge=0)
    trades_seen: int = Field(..., ge=0)
    realized_metrics: dict = Field(
        ...,
        description="Realized metrics (return_pct, sharpe_proxy, hit_rate, max_drawdown_pct, expectancy)",
    )

    model_config = {"extra": "forbid"}


class ForwardMetricsResponse(BaseModel):
    """Response from forward metrics submission."""
    status: str  # accepted
    observation_id: str


# =============================================================================
# Endpoint
# =============================================================================


@router.post(
    "/metrics",
    response_model=ForwardMetricsResponse,
    responses={
        200: {"description": "Metrics accepted"},
        404: {"description": "Record not found or not active"},
        409: {"description": "Duplicate observation (record_id, ts)"},
        503: {"description": "Service unavailable"},
    },
    summary="Submit forward run metrics",
    description="""
Submit realized metrics from a forward run (paper/shadow/live).

**Guarantees:**
- Idempotency via (record_id, ts) unique constraint
- Returns 409 Conflict if duplicate
- Returns 404 if record_id not found or not active
""",
)
async def submit_metrics(request: ForwardMetricsRequest) -> ForwardMetricsResponse:
    """Submit forward run metrics."""
    repo = _get_repository()

    # Check record exists and is active
    record = await repo.get_record_by_id(request.record_id)
    if record is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail={"error": "Record not found", "code": "RECORD_NOT_FOUND"},
        )

    if record.status != RecordStatus.ACTIVE:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail={
                "error": f"Record is not active (status={record.status})",
                "code": "RECORD_NOT_ACTIVE",
            },
        )

    # Create observation
    obs = RecommendationObservation(
        record_id=request.record_id,
        ts=request.ts,
        bars_seen=request.bars_seen,
        trades_seen=request.trades_seen,
        realized_metrics_json=request.realized_metrics,
    )

    try:
        obs_id = await repo.add_observation(obs)
    except Exception as e:
        # Check for unique violation
        if "unique" in str(e).lower() or "duplicate" in str(e).lower():
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail={
                    "error": "Duplicate observation for (record_id, ts)",
                    "code": "DUPLICATE_OBSERVATION",
                },
            )
        raise

    logger.info(
        "forward_metrics_accepted",
        record_id=str(request.record_id),
        ts=request.ts.isoformat(),
        bars_seen=request.bars_seen,
        trades_seen=request.trades_seen,
    )

    return ForwardMetricsResponse(
        status="accepted",
        observation_id=str(obs_id),
    )
```

**Step 4: Run tests**

Run: `pytest tests/unit/test_forward_metrics_router.py -v`
Expected: All tests PASS

**Step 5: Commit**

```bash
git add app/routers/forward_metrics.py tests/unit/test_forward_metrics_router.py
git commit -m "feat(api): add POST /forward/metrics endpoint"
```

---

## Phase 5: Enhanced Recommend Pipeline

### Task 5.1: Add v1.5 Fields to Recommend Response

**Files:**
- Modify: `app/services/kb/recommend.py`
- Modify: `app/routers/kb_trials.py`
- Test: `tests/unit/test_kb_recommend_v15.py`

This task integrates the v1.5 primitives into the existing recommend pipeline. The changes include:

1. Add `regime_fit_confidence` computation
2. Add `regime_distance_z` using cluster stats + neighbors
3. Add duration fields (half_life, expected_remaining)
4. Add FSM state exposure (stable_regime_key, raw_regime_key)
5. Add window metadata

**[Detailed steps follow same TDD pattern - abbreviated for length]**

---

## Phase 6: Backfill Jobs

### Task 6.1: Cluster Stats Backfill Job

**Files:**
- Create: `app/jobs/backfill_cluster_stats.py`
- Test: `tests/unit/test_backfill_cluster_stats.py`

**Purpose:** Aggregate existing trial regime features into cluster stats by (strategy_entity_id, timeframe, regime_key).

**[Detailed steps follow same TDD pattern]**

---

### Task 6.2: Duration Stats Backfill Job

**Files:**
- Create: `app/jobs/backfill_duration_stats.py`
- Test: `tests/unit/test_backfill_duration_stats.py`

**Purpose:** Run hysteresis FSM over historical OHLCV to segment regimes and compute duration distributions.

**[Detailed steps follow same TDD pattern]**

---

## Phase 7: Golden Tests

### Task 7.1: FSM Golden Tests

**Files:**
- Create: `tests/golden/test_fsm_scenarios.py`
- Create: `tests/golden/fixtures/fsm_*.json`

**Purpose:** Deterministic FSM behavior verification with recorded scenarios.

```python
# tests/golden/test_fsm_scenarios.py
"""Golden tests for FSM determinism."""

import json
import pytest
from pathlib import Path

from app.services.kb.regime_fsm import RegimeFSM, FSMConfig


FIXTURES_DIR = Path(__file__).parent / "fixtures"


def load_scenario(name: str) -> dict:
    """Load golden scenario from JSON."""
    path = FIXTURES_DIR / f"fsm_{name}.json"
    with open(path) as f:
        return json.load(f)


class TestFSMGoldenScenarios:
    """Golden tests for FSM behavior."""

    @pytest.mark.parametrize("scenario_name", [
        "stable_regime",
        "clean_transition",
        "flicker_suppressed",
        "low_confidence_ignored",
        "hysteresis_boundary",
    ])
    def test_scenario(self, scenario_name: str):
        """Run golden scenario and verify outputs match."""
        scenario = load_scenario(scenario_name)

        config = FSMConfig(**scenario["config"])
        fsm = RegimeFSM(config=config)

        for i, step in enumerate(scenario["steps"]):
            event = fsm.update(
                raw_regime_key=step["raw_key"],
                confidence=step["confidence"],
            )

            state = fsm.get_state()
            expected = step["expected_state"]

            assert state.stable_regime_key == expected["stable_key"], f"Step {i}: stable_key mismatch"
            assert state.candidate_count == expected["candidate_count"], f"Step {i}: candidate_count mismatch"
            assert (event is not None) == expected.get("transition", False), f"Step {i}: transition mismatch"
```

---

### Task 7.2: Distance Z-Score Golden Tests

**Files:**
- Create: `tests/golden/test_distance_z_scenarios.py`
- Create: `tests/golden/fixtures/distance_*.json`

**Purpose:** Verify distance z-score computation stability across scenarios including backoff.

---

## Summary

**Total Tasks:** 16 (across 7 phases)

**Phase Order:**
1. Database schema (migration)
2. Core types (regime_key, FSM, distance)
3. Repository layer (cluster_stats, duration_stats, records)
4. API endpoints (forward_metrics)
5. Enhanced recommend pipeline
6. Backfill jobs
7. Golden tests

**Estimated Commits:** 16 feature commits + integration

---

## Next Steps

Plan complete and saved to `docs/plans/2026-01-09-v1.5-implementation-plan.md`. Two execution options:

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

Which approach?
