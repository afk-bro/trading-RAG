# Trading RAG Pipeline Environment Configuration
# Copy this file to .env and fill in your actual values

# ===========================================
# REQUIRED: Supabase Configuration
# ===========================================
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# ===========================================
# REQUIRED: Database Connection
# ===========================================
# Get connection string from Supabase Dashboard: Project Settings > Database > Connection string
#
# Option 1: Transaction Pooler (RECOMMENDED for most deployments)
# - Uses pgbouncer in transaction mode (port 6543)
# - Format: postgresql://postgres.[project-ref]:[password]@[region].pooler.supabase.com:6543/postgres
# - Note: asyncpg uses statement_cache_size=0 for pgbouncer compatibility
# DATABASE_URL=postgresql://postgres.your-project-ref:your-password@aws-0-us-east-1.pooler.supabase.com:6543/postgres
#
# Option 2: Session Pooler (port 5432)
# - Uses pgbouncer in session mode
# DATABASE_URL=postgresql://postgres.your-project-ref:your-password@aws-0-us-east-1.pooler.supabase.com:5432/postgres
#
# Option 3: Direct Connection (if enabled on your Supabase plan)
# - Bypasses pgbouncer, connects directly to Postgres
# - Format: postgresql://postgres:[password]@db.[project-ref].supabase.co:5432/postgres
# DATABASE_URL=postgresql://postgres:your-password@db.your-project-ref.supabase.co:5432/postgres

# Alternative: Supabase database password only (used with SUPABASE_URL to construct connection)
# SUPABASE_DB_PASSWORD=your-supabase-database-password

# ===========================================
# OPTIONAL: LLM Provider Configuration
# ===========================================
# Enables mode=answer queries (LLM-generated responses with citations).
# Without an API key, semantic search (mode=retrieve) works fully.
# When mode=answer is called without a key, returns retrieved chunks
# with a message indicating generation is disabled.

# Provider selection: auto | anthropic | openai | openrouter
# auto: prefers Anthropic > OpenAI > OpenRouter (first available key)
LLM_PROVIDER=auto

# Anthropic API key (preferred, direct SDK access)
# ANTHROPIC_API_KEY=your-anthropic-api-key

# OpenAI API key (direct access to GPT models)
# OPENAI_API_KEY=your-openai-api-key

# OpenRouter API key (proxy access to multiple providers, including FREE models)
# OPENROUTER_API_KEY=your-openrouter-api-key

# If true, fail startup when no LLM key is configured (default: false)
# LLM_REQUIRED=false

# Kill switch to disable LLM regardless of keys (default: true)
# LLM_ENABLED=true

# ===========================================
# OPTIONAL: Service Configuration
# ===========================================
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000
LOG_LEVEL=INFO

# ===========================================
# OPTIONAL: Qdrant Configuration
# ===========================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_ACTIVE=kb_nomic_embed_text_v1

# ===========================================
# OPTIONAL: Ollama Configuration
# ===========================================
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
EMBED_MODEL=nomic-embed-text
EMBED_BATCH_SIZE=32

# ===========================================
# OPTIONAL: LLM Model Configuration
# ===========================================
# Model for answer generation (user-facing output)
# Aliases (e.g., claude-sonnet-4) auto-update; full versions pin behavior
ANSWER_MODEL=claude-sonnet-4

# Model for reranking/scoring (cheaper/faster)
# Set to empty to reuse ANSWER_MODEL
RERANK_MODEL=claude-haiku-3-5

# --- FREE OpenRouter Models (recommended for testing/dev) ---
# Set LLM_PROVIDER=openrouter and use these free models:
# ANSWER_MODEL=google/gemma-3-27b-it:free    # Best free quality, huge context
# ANSWER_MODEL=google/gemma-3-12b-it:free    # Faster alternative
# RERANK_MODEL=google/gemini-2.0-flash-exp:free  # Fast extraction/verification

# Maximum context tokens for LLM
MAX_CONTEXT_TOKENS=8000

# ===========================================
# OPTIONAL: Database Connection Pool
# ===========================================
DB_POOL_MIN_SIZE=5
DB_POOL_MAX_SIZE=20

# ===========================================
# OPTIONAL: YouTube API (for metadata enrichment)
# ===========================================
# YOUTUBE_API_KEY=your-youtube-api-key

# ===========================================
# OPTIONAL: Chunking Configuration
# ===========================================
CHUNK_MAX_TOKENS=512
CHUNK_OVERLAP_TOKENS=50
# Tokenizer encoding: cl100k_base (GPT-4), p50k_base (GPT-3), r50k_base (older models)
CHUNK_TOKENIZER_ENCODING=cl100k_base

# ===========================================
# OPTIONAL: Timeouts (in seconds)
# ===========================================
QDRANT_TIMEOUT=30
OLLAMA_TIMEOUT=120
LLM_TIMEOUT=60

# ===========================================
# OPTIONAL: Request Limits
# ===========================================
# Maximum request body size in bytes (default: 10MB = 10485760)
MAX_REQUEST_BODY_SIZE=10485760

# ===========================================
# OPTIONAL: API Key Authentication
# ===========================================
# Set API_KEY to require authentication for all non-public endpoints
# Public endpoints (no auth required): /health, /metrics, /docs, /openapi.json, /redoc, /
# API_KEY=your-secure-api-key
# API_KEY_HEADER_NAME=X-API-Key

# ===========================================
# PRODUCTION: Security & Operations
# ===========================================
# Admin token for /admin/* endpoints (REQUIRED in production)
# Generate with: openssl rand -hex 32
# ADMIN_TOKEN=your-secure-admin-token

# Disable API docs in production
# DOCS_ENABLED=false

# Rate limiting (enabled by default)
# RATE_LIMIT_ENABLED=true

# CORS origins (comma-separated, use specific origins in production)
# CORS_ORIGINS=https://your-app.com,https://admin.your-app.com

# Configuration profile for logging/monitoring
# CONFIG_PROFILE=production

# ===========================================
# PRODUCTION: Build Metadata (set by CI/CD)
# ===========================================
# GIT_SHA=abc123def
# BUILD_TIME=2025-01-09T12:00:00Z

# ===========================================
# PRODUCTION: Sentry Monitoring
# ===========================================
# SENTRY_DSN=https://xxx@sentry.io/yyy
# SENTRY_ENVIRONMENT=production
# SENTRY_TRACES_SAMPLE_RATE=0.1
# SENTRY_PROFILES_SAMPLE_RATE=0.1
