<project_specification>
  <project_name>trading-RAG - Multi-Tenant Trading Research Platform</project_name>

  <overview>
    A multi-tenant platform for crypto trading research, backtesting, and strategy evaluation.
    Combines Retrieval-Augmented Generation (RAG) for knowledge management with a full
    backtesting engine, walk-forward optimization, and operational alerting. Built on FastAPI
    with Supabase Postgres (source of truth), Qdrant (vector index), and Ollama (embeddings).
    Prioritizes reproducibility, observability, and workspace isolation.
  </overview>

  <technology_stack>
    <backend>
      <framework>Python FastAPI</framework>
      <async>asyncio + httpx + asyncpg</async>
      <validation>Pydantic v2 with strict types</validation>
      <port>8000</port>
    </backend>
    <databases>
      <primary>Supabase Postgres - workspaces, documents, chunks, backtests, ops_alerts</primary>
      <vectors>Qdrant (local Docker) - embedding vectors with payload filtering</vectors>
      <connection>asyncpg for raw SQL, transaction pooler (port 6543)</connection>
    </databases>
    <embeddings>
      <provider>Ollama (local)</provider>
      <model>nomic-embed-text (768 dimensions)</model>
    </embeddings>
    <llm>
      <provider>OpenRouter API (optional)</provider>
      <model>anthropic/claude-sonnet-4 (configurable)</model>
    </llm>
    <extraction>
      <pdf>PyMuPDF (default) | pdfplumber</pdf>
      <youtube>youtube-transcript-api</youtube>
    </extraction>
    <jobs>
      <scheduler>pg_cron (PostgreSQL extension)</scheduler>
      <queue>jobs table with async workers</queue>
    </jobs>
    <infrastructure>
      <containerization>Docker Compose</containerization>
      <network>rag-net (Qdrant, Ollama, trading-rag-svc)</network>
    </infrastructure>
  </technology_stack>

  <core_features>
    <workspace_control_plane>
      - Multi-tenant isolation via workspace_id on all tables
      - Configurable defaults: collection, embed_provider, embed_model
      - Control flags: is_active, ingestion_enabled
      - Flexible config JSONB for chunking, retrieval, PDF settings
    </workspace_control_plane>

    <rag_pipeline>
      <ingestion>
        - YouTube video/playlist transcript extraction
        - PDF extraction with page-aware chunking
        - Pine Script registry ingestion
        - Generic document ingestion (article, note, transcript)
        - Content hashing for deduplication
        - Idempotency via idempotency_key or canonical_url
      </ingestion>
      <chunking>
        - Token-aware chunking (~512 tokens max)
        - Page-aware chunking for PDFs
        - Timestamp-aware chunking for YouTube
        - Metadata extraction (symbols, entities, topics)
      </chunking>
      <embedding>
        - Batch embedding via Ollama
        - Model migration support via chunk_vectors table
        - Collection per embedding model
      </embedding>
      <retrieval>
        - Semantic vector search
        - Filter mapping: source_types, symbols, topics, date range
        - Hydration from Postgres with ranking preservation
        - Citation URL builder with timestamp/page locators
      </retrieval>
      <answer_generation>
        - Mode: "retrieve" (chunks only) vs "answer" (LLM synthesis)
        - Graceful degradation without OPENROUTER_API_KEY
      </answer_generation>
    </rag_pipeline>

    <backtesting_engine>
      <strategy_lifecycle>
        - Strategy definitions with versioned code
        - Parameter sets stored separately
        - Enable/disable per workspace
      </strategy_lifecycle>
      <backtest_runner>
        - Deterministic execution
        - Explicit fee model (maker/taker)
        - Explicit slippage model
        - Position sizing rules
      </backtest_runner>
      <metrics>
        - Total return, max drawdown, Sharpe ratio
        - Win rate, profit factor, trade count
        - Buy & Hold benchmark comparison
      </metrics>
      <tuning>
        - Parameter sweep with grid search
        - Tune sessions with parameter combinations
        - Top performer selection
      </tuning>
      <wfo>
        - Walk-forward optimization with rolling windows
        - Train/test segment separation
        - Per-fold metrics storage
        - Aggregate selection logic
      </wfo>
      <leaderboard>
        - Global strategy ranking
        - Performance metrics comparison
      </leaderboard>
    </backtesting_engine>

    <ops_alerts>
      <rule_types>
        - health_degraded (DB, vector store, services)
        - coverage_weakness
        - confidence_drop
        - drift_spike
      </rule_types>
      <evaluation>
        - Automated evaluation via pg_cron scheduled jobs
        - Deduplication via dedupe_key
        - Severity levels: critical, high, medium, low
        - Severity escalation tracking
      </evaluation>
      <notifications>
        - Telegram delivery with topic routing
        - Activation notifications (new alerts)
        - Recovery notifications (resolved alerts)
        - Escalation notifications (severity bump)
        - Idempotent delivery (no duplicates)
        - Delivery tracking columns (notified_at, recovery_notified_at, escalation_notified_at)
      </notifications>
      <management>
        - Acknowledge alerts
        - Resolve alerts
        - Reopen alerts
        - Priority scoring
      </management>
    </ops_alerts>

    <job_system>
      <job_types>
        - ingest_upload, ingest_youtube, extract_pdf
        - chunk, embed, upsert_qdrant
        - reindex_document, delete_document
        - backtest_run, tune_session, wfo_run
        - ops_alert_eval
      </job_types>
      <job_states>
        - queued, running, succeeded, failed, cancelled
      </job_states>
      <features>
        - Progress reporting
        - Automatic retries with bounded attempts
        - Dead-letter queue for failed jobs
        - pg_cron scheduling for recurring jobs
      </features>
    </job_system>

    <admin_ui>
      <pages>
        - System health dashboard
        - Coverage cockpit
        - Ops alerts management
        - Ingest UI (YouTube, PDF, Pine)
        - Backtest tuning sessions
        - Backtest detail pages
        - WFO results
        - Leaderboard
      </pages>
      <authentication>
        - X-Admin-Token header required
        - Workspace-scoped data access
      </authentication>
    </admin_ui>

    <observability>
      - Structured JSON logging with request_id
      - Timing spans for pipeline stages
      - Health endpoint with latency_ms per dependency
      - Prometheus metrics endpoint
      - Error tracking with retryable flag
    </observability>
  </core_features>

  <database_schema>
    <tables>
      <workspaces>
        - id, name, slug, owner_id
        - default_collection, default_embed_provider, default_embed_model
        - is_active, ingestion_enabled
        - config (jsonb)
      </workspaces>
      <documents>
        - id, workspace_id, source_url, canonical_url, source_type
        - content_hash, title, author, published_at
        - status (active/superseded/deleted)
        - unique (workspace_id, source_type, canonical_url)
      </documents>
      <chunks>
        - id, doc_id, workspace_id, chunk_index, content
        - token_count, page_start, page_end
        - time_start_secs, time_end_secs, locator_label
        - symbols[], entities[], topics[]
      </chunks>
      <chunk_vectors>
        - id, chunk_id, workspace_id
        - embed_provider, embed_model, collection
        - qdrant_point_id, status
      </chunk_vectors>
      <backtest_runs>
        - id, workspace_id, strategy_id, strategy_version
        - parameters (jsonb), status, metrics (jsonb)
        - start_time, end_time
      </backtest_runs>
      <tune_sessions>
        - id, workspace_id, strategy_id
        - parameter_grid (jsonb), status
        - best_params (jsonb), best_metrics (jsonb)
      </tune_sessions>
      <wfo_runs>
        - id, workspace_id, strategy_id
        - window_config (jsonb), folds (jsonb)
        - aggregate_metrics (jsonb)
      </wfo_runs>
      <ops_alerts>
        - id, workspace_id, rule_type, severity, status
        - dedupe_key, payload (jsonb), source, job_run_id
        - occurrence_count, acknowledged_at, resolved_at
        - notified_at, recovery_notified_at, escalated_at, escalation_notified_at
        - telegram_message_id, delivery_attempts, last_delivery_error
      </ops_alerts>
      <jobs>
        - id, workspace_id, job_type, status
        - payload (jsonb), result (jsonb)
        - progress, error, retries
        - created_at, started_at, completed_at
      </jobs>
    </tables>
  </database_schema>

  <api_endpoints>
    <health>
      - GET /health
    </health>
    <ingestion>
      - POST /ingest
      - POST /sources/youtube/ingest
      - POST /sources/pdf/ingest
      - POST /sources/pine/ingest
    </ingestion>
    <query>
      - POST /query
    </query>
    <reembed>
      - POST /reembed
    </reembed>
    <jobs>
      - GET /jobs/{job_id}
    </jobs>
    <backtests>
      - POST /backtests/tune
      - GET /backtests/tunes
      - POST /backtests/wfo
      - GET /backtests/leaderboard
    </backtests>
    <execution>
      - POST /execute/intents
      - GET /execute/paper/state/{workspace_id}
    </execution>
    <admin>
      - GET /admin/system/health
      - GET /admin/coverage/cockpit
      - GET /admin/ops-alerts
      - POST /admin/ops-alerts/{alert_id}/acknowledge
      - POST /admin/ops-alerts/{alert_id}/resolve
      - POST /admin/ops-alerts/{alert_id}/reopen
      - GET /admin/backtests/*
      - GET /admin/ingest
    </admin>
    <metrics>
      - GET /metrics
    </metrics>
  </api_endpoints>

  <success_criteria>
    <functionality>
      - YouTube/PDF ingestion works end-to-end
      - Query returns relevant chunks with correct ranking
      - Backtests are reproducible across runs
      - Alerts fire automatically and deliver to Telegram
      - Admin UI allows full inspection and triage
    </functionality>
    <reliability>
      - Idempotent operations (re-running same ingest is safe)
      - Graceful handling of missing transcripts/extraction errors
      - Job status accurately tracks async operations
      - Notification delivery is idempotent (no duplicates)
    </reliability>
    <performance>
      - Health endpoint latency < 100ms
      - Ingest pipeline < 30s for typical video
      - Query latency p95 < 2 seconds
    </performance>
    <observability>
      - All requests have request_id
      - Structured JSON logs for debugging
      - Health endpoint shows all dependency status
      - Metrics available for monitoring
    </observability>
    <multi_tenancy>
      - Workspace isolation enforced at data layer
      - Cross-workspace queries impossible
    </multi_tenancy>
  </success_criteria>
</project_specification>
