<project_specification>
  <project_name>Trading RAG Pipeline - Finance Knowledge Base</project_name>

  <overview>
    Build a local RAG (Retrieval-Augmented Generation) pipeline for finance and trading knowledge.
    The system ingests YouTube transcripts (and other documents) via n8n orchestration, processes
    them through a FastAPI service that handles chunking, embedding, and storage. Documents and
    metadata are stored in Supabase Postgres (source of truth), vectors in Qdrant (index).
    Embeddings are generated locally via Ollama (zero cost, data stays local), while LLM
    generation uses OpenRouter API (quality where it matters). The architecture prioritizes
    idempotency, observability, and clean model migrations.
  </overview>

  <technology_stack>
    <orchestration>
      <platform>n8n (self-hosted, Docker)</platform>
      <trigger>Google Sheets - YouTube Ingest Queue</trigger>
      <pattern>State machine with lease-based locking</pattern>
      <responsibilities>Watch queue, lock rows, call service, update status, fan out playlists</responsibilities>
    </orchestration>
    <backend>
      <framework>Python FastAPI</framework>
      <async>asyncio + httpx + asyncpg</async>
      <validation>Pydantic v2 with strict types</validation>
      <port>8000</port>
    </backend>
    <databases>
      <primary>Supabase Postgres (cloud) - documents, chunks, chunk_vectors</primary>
      <vectors>Qdrant (local Docker) - embedding vectors with payload filtering</vectors>
      <connection>asyncpg for raw SQL, Supabase client for auth/management</connection>
    </databases>
    <embeddings>
      <provider>Ollama (local)</provider>
      <model>nomic-embed-text (768 dimensions)</model>
      <benefits>Zero marginal cost, data stays local, re-embed freely</benefits>
    </embeddings>
    <llm>
      <provider>OpenRouter API</provider>
      <model>anthropic/claude-sonnet-4 (configurable)</model>
      <use_cases>Query answering, reranking, entity extraction</use_cases>
    </llm>
    <infrastructure>
      <containerization>Docker Compose</containerization>
      <network>rag-net (Qdrant, Ollama, trading-rag-svc)</network>
      <external>n8n (separate compose, calls via localhost:8000)</external>
    </infrastructure>
  </technology_stack>

  <prerequisites>
    <environment_setup>
      - Docker and Docker Compose installed
      - Supabase project with Postgres database
      - Google Cloud project with Sheets API enabled
      - n8n instance running (existing docker-compose in ~/dev/automation-infra/n8n)
      - OpenRouter API key for LLM generation
      - YouTube Data API key (optional, for metadata enrichment)
    </environment_setup>
    <configuration>
      - .env file with SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY
      - .env file with OPENROUTER_API_KEY
      - Google Sheets OAuth credentials configured in n8n
      - Ollama model pulled: `ollama pull nomic-embed-text`
    </configuration>
  </prerequisites>

  <core_features>
    <youtube_ingestion>
      - Parse YouTube URLs (single video or playlist)
      - Extract video metadata (title, channel, published_at, duration)
      - Fetch transcripts with retry + exponential backoff
      - Handle missing transcripts gracefully (mark as terminal error)
      - Playlist expansion into individual video rows
      - Timestamp-aware chunking with locator labels
      - Normalize transcript artifacts ([Music], repeated phrases)
    </youtube_ingestion>

    <document_ingestion>
      - Generic /ingest endpoint for non-YouTube sources
      - Support for PDF, article, note, transcript source types
      - Pre-chunked input support (caller provides chunks)
      - Content hashing for deduplication
      - Idempotency via idempotency_key or canonical_url
      - Write-new-first pattern for safe updates
    </document_ingestion>

    <chunking_pipeline>
      - Token-aware chunking (~512 tokens max)
      - Preserve timestamps for YouTube/podcast content
      - Generate locator_label ("12:34", "p. 17")
      - Count tokens per chunk
      - Extract version tracking for re-chunking
    </chunking_pipeline>

    <metadata_extraction>
      - Symbols: regex + ticker allowlist, uppercase normalization
      - Entities: keyword match (Fed, Powell, FOMC, central banks, companies)
      - Topics: keyword classifier (macro, earnings, tech, rates, etc.)
      - Speaker detection (for multi-speaker content)
      - Quality score estimation (transcript confidence)
    </metadata_extraction>

    <embedding_pipeline>
      - Batch embedding via Ollama
      - Dimension detection at startup
      - Collection validation (dim + distance match)
      - Pluggable providers (ollama, openai)
      - chunk_vectors table for model migration support
    </embedding_pipeline>

    <vector_storage>
      - Qdrant collection per embedding model
      - Lean payload (filter keys only, no content)
      - Payload indexes on workspace_id, published_at, source_type, symbols, topics
      - Point ID = chunk_id (UUID, clean 1:1 mapping)
      - Write-new-first, delete-old-after-success pattern
    </vector_storage>

    <retrieval>
      - Semantic search with configurable retrieve_k and top_k
      - Filter mapping: QueryFilters → Qdrant payload filters
      - symbols_mode: "any" vs "all" matching
      - Date range filtering (published_from, published_to)
      - Hydration from Postgres with preserved ranking order
      - Citation URL builder with timestamp/page locators
    </retrieval>

    <reranking>
      - Pluggable rerank providers (none, api, local)
      - Over-fetch pattern: retrieve_k > top_k
      - Optional LLM-as-reranker for top chunks
    </reranking>

    <answer_generation>
      - Mode: "retrieve" (chunks only) vs "answer" (LLM synthesis)
      - Configurable answer_model and max_context_tokens
      - Citation format: [1], [2], etc.
      - Source attribution with clickable URLs
    </answer_generation>

    <model_migration>
      - /reembed endpoint for re-embedding with new model
      - Target collection naming: kb_{model}_{version}
      - Async job execution with status tracking
      - chunk_vectors table tracks embeddings per model/collection
      - Swap active collection via env var
    </model_migration>

    <observability>
      - Structured logging with request_id
      - Timing spans for pipeline stages
      - Health endpoint with latency_ms per dependency
      - Service version in health response
      - Error tracking with retryable flag
    </observability>
  </core_features>

  <database_schema>
    <tables>
      <documents>
        - id (uuid pk), workspace_id (uuid)
        - source_url, canonical_url (not null), source_type
        - content_hash (indexed, not unique)
        - title, author, channel, published_at, language, duration_secs
        - video_id, playlist_id (YouTube-specific)
        - status (active/superseded/deleted), version
        - created_at, updated_at, last_indexed_at
        - unique (workspace_id, source_type, canonical_url)
      </documents>

      <chunks>
        - id (uuid pk), doc_id (fk), workspace_id
        - chunk_index, content, content_hash, token_count, section
        - time_start_secs, time_end_secs (YouTube/podcast)
        - page_start, page_end (PDF)
        - locator_label ("12:34", "p. 17")
        - speaker, symbols[], entities[], topics[]
        - quality_score
        - created_at, updated_at
        - unique (doc_id, chunk_index)
        - composite FK (doc_id, workspace_id) → documents(id, workspace_id)
      </chunks>

      <chunk_vectors>
        - id (uuid pk), chunk_id (fk), workspace_id
        - embed_provider, embed_model, collection, vector_dim
        - qdrant_point_id (text)
        - status (pending/indexed/failed), indexed_at, error
        - created_at
        - unique (chunk_id, embed_provider, embed_model, collection)
      </chunk_vectors>
    </tables>

    <indexes>
      <documents>
        - (workspace_id, published_at desc)
        - (workspace_id, source_type)
        - (content_hash)
        - (workspace_id, source_url)
      </documents>
      <chunks>
        - (workspace_id, doc_id)
        - gin(symbols), gin(topics), gin(entities)
      </chunks>
      <chunk_vectors>
        - (chunk_id)
        - (workspace_id, collection, status)
      </chunk_vectors>
    </indexes>
  </database_schema>

  <api_endpoints_summary>
    <youtube>
      - POST /sources/youtube/ingest
        Request: { workspace_id, url, idempotency_key? }
        Response: { doc_id, video_id, playlist_id, status, retryable, chunks_created, is_playlist, video_urls? }
    </youtube>

    <ingestion>
      - POST /ingest
        Request: { workspace_id, idempotency_key?, content_hash?, source, content, metadata, chunks? }
        Response: { doc_id, chunks_created, vectors_created, status }
    </ingestion>

    <query>
      - POST /query
        Request: { workspace_id, question, mode, filters, retrieve_k, top_k, rerank, answer_model?, max_context_tokens? }
        Response: { results: [ChunkResult], answer? }
        Filters: { source_types[], symbols[], symbols_mode, topics[], entities[], authors[], published_from, published_to }
    </query>

    <reembed>
      - POST /reembed
        Request: { workspace_id, target_collection, embed_provider, embed_model, doc_ids? }
        Response: { job_id, chunks_queued, status: "started" }
    </reembed>

    <jobs>
      - GET /jobs/{job_id}
        Response: { job_id, status, progress, error? }
    </jobs>

    <health>
      - GET /health
        Response: { status, qdrant, supabase, ollama, active_collection, embed_model, latency_ms, version }
    </health>
  </api_endpoints_summary>

  <n8n_workflow>
    <google_sheet_schema>
      - url (string): YouTube URL
      - status (enum): queued, processing, ingested, error, retry, queued_children
      - run_id (uuid): Current execution ID
      - attempt_count (int): Retry tracking
      - started_at, finished_at, lease_expires_at (timestamps)
      - video_id, playlist_id (strings)
      - doc_id (uuid): Returned from service
      - error_reason (string): no_transcript, rate_limited, network_error
    </google_sheet_schema>

    <workflow_nodes>
      - Trigger: Google Sheets Trigger (watch for new/updated rows)
      - Lock Row: Code node (set status=processing, lease_expires_at)
      - Call Service: HTTP Request (POST /sources/youtube/ingest)
      - Handle Response: Switch node (success vs playlist vs error)
      - Update Sheet: Google Sheets (write status, doc_id, error_reason)
      - Fan Out Playlist: Code node (create child rows with status=queued)
      - Error Handler: Error Trigger (catch failures, update sheet)
    </workflow_nodes>

    <state_machine>
      - queued → processing (lock acquired)
      - processing → ingested (success)
      - processing → error (terminal failure)
      - processing → retry (retryable failure)
      - processing → queued_children (playlist expanded)
      - retry → processing (lease expired or manual retry)
    </state_machine>

    <lock_pattern>
      - Eligible: status IN (queued, retry) OR (status=processing AND lease_expires_at < now)
      - Lock: set status=processing, run_id, attempt_count++, started_at, lease_expires_at (now + 15min)
      - Self-healing: expired leases can be reprocessed
    </lock_pattern>

    <playlist_handling>
      - Service returns is_playlist=true with video_urls[]
      - n8n writes child rows with status=queued, playlist_id set
      - Parent row marked as queued_children
      - Idempotent: check existing video_ids before inserting
    </playlist_handling>
  </n8n_workflow>

  <qdrant_configuration>
    <collection_naming>
      - Pattern: kb_{embed_model}_{version}
      - Example: kb_nomic_embed_text_v1
      - Switch models by creating new collection, running /reembed, swapping QDRANT_COLLECTION_ACTIVE
    </collection_naming>

    <collection_settings>
      - vectors.size: 768 (nomic-embed-text)
      - vectors.distance: Cosine
      - Detect dimension at startup, validate match
    </collection_settings>

    <payload_structure>
      - workspace_id (string)
      - doc_id (string)
      - source_type (string)
      - published_at (int, unix timestamp)
      - author, channel (strings)
      - symbols, topics, entities (string arrays)
      - time_start_secs (int, for timestamp links)
      - Total: ~200-400 bytes per point
    </payload_structure>

    <payload_indexes>
      - workspace_id (keyword) - critical
      - published_at (integer)
      - source_type (keyword)
      - symbols (keyword array)
      - topics (keyword array)
      - entities (keyword array)
    </payload_indexes>
  </qdrant_configuration>

  <data_flows>
    <ingest_flow>
      1. Dedupe check: hash content, check idempotency_key or (workspace, canonical_url)
      2. Chunk: split by tokens, preserve timestamps, compute locator_label
      3. Extract: symbols (regex), entities (keywords), topics (classifier)
      4. Embed: batch embed via Ollama, validate dimension
      5. Store: insert doc → insert chunks → upsert Qdrant → insert chunk_vectors
      6. Cleanup: if update, delete/supersede old chunks after success
      7. Return: { doc_id, chunks_created, vectors_created, status }
    </ingest_flow>

    <query_flow>
      1. Embed query: same embedder as ingestion
      2. Qdrant search: retrieve_k results with filters
      3. Rerank: optional, re-sort by rerank score
      4. Truncate: take top_k
      5. Hydrate: SELECT from Postgres, preserve ranking with array_position
      6. Format citations: build URL with timestamp/page locator
      7. Generate answer: if mode="answer", pass to LLM
      8. Return: { results, answer }
    </query_flow>

    <youtube_flow>
      1. Parse URL: detect video vs playlist, extract IDs
      2. If playlist: fetch video list, return video_urls for fan-out
      3. Fetch metadata: title, channel, published_at, duration
      4. Fetch transcript: with retry + backoff, handle missing
      5. Normalize: clean artifacts, collapse whitespace
      6. Chunk: by tokens, preserve timestamps
      7. Ingest: via standard pipeline
      8. Return: { doc_id, video_id, status }
    </youtube_flow>
  </data_flows>

  <implementation_steps>
    <step number="1">
      <title>Infrastructure Setup</title>
      <tasks>
        - Create docker-compose.rag.yml with Qdrant, Ollama, service placeholder
        - Start Qdrant and Ollama containers
        - Pull nomic-embed-text model in Ollama
        - Create rag-net Docker network
        - Verify connectivity between containers
      </tasks>
    </step>

    <step number="2">
      <title>Supabase Schema</title>
      <tasks>
        - Create documents table with indexes
        - Create chunks table with composite FK
        - Create chunk_vectors table
        - Add updated_at trigger function
        - Verify constraints and indexes
      </tasks>
    </step>

    <step number="3">
      <title>Service Scaffold</title>
      <tasks>
        - Initialize FastAPI project structure
        - Create config.py with Pydantic Settings
        - Create schemas.py with request/response models
        - Implement GET /health endpoint
        - Set up asyncpg connection pool
        - Set up Qdrant client
        - Add structured logging
      </tasks>
    </step>

    <step number="4">
      <title>Core Ingestion Pipeline</title>
      <tasks>
        - Implement content hasher
        - Implement chunker with token counting
        - Implement metadata extractor (symbols, entities, topics)
        - Create Ollama embedder with batch support
        - Implement repositories (documents, chunks, vectors)
        - Implement Qdrant operations (upsert, delete)
        - Wire up POST /ingest endpoint
        - Add idempotency and dedupe logic
      </tasks>
    </step>

    <step number="5">
      <title>YouTube Module</title>
      <tasks>
        - Implement URL parser (video vs playlist detection)
        - Implement metadata fetcher
        - Implement transcript fetcher with retry
        - Implement transcript normalizer
        - Implement timestamp-aware chunker
        - Wire up POST /sources/youtube/ingest
        - Handle playlist expansion
      </tasks>
    </step>

    <step number="6">
      <title>Query Pipeline</title>
      <tasks>
        - Implement query embedding
        - Implement Qdrant search with filter mapping
        - Implement Postgres hydration with array_position
        - Implement citation URL builder
        - Add optional LLM answer generation
        - Wire up POST /query endpoint
      </tasks>
    </step>

    <step number="7">
      <title>n8n Workflow</title>
      <tasks>
        - Create Google Sheet with schema columns
        - Build workflow: trigger → lock → call service → update sheet
        - Implement lock pattern with lease_expires_at
        - Implement playlist fan-out logic
        - Add error handling and retry logic
        - Test end-to-end with sample videos
      </tasks>
    </step>

    <step number="8">
      <title>Reembed and Jobs</title>
      <tasks>
        - Implement job models and in-memory runner
        - Wire up POST /reembed endpoint
        - Implement GET /jobs/{job_id} endpoint
        - Test model migration workflow
      </tasks>
    </step>

    <step number="9">
      <title>Polish and Testing</title>
      <tasks>
        - Add comprehensive error handling
        - Add request ID middleware
        - Add timing spans to observability
        - Write integration tests for key flows
        - Document API with examples
        - Performance testing with larger corpus
      </tasks>
    </step>
  </implementation_steps>

  <success_criteria>
    <functionality>
      - YouTube transcript ingestion works end-to-end
      - Playlist expansion creates correct child rows
      - Deduplication prevents duplicate documents
      - Query returns relevant chunks with correct ranking
      - Citations include clickable timestamp links
      - Model migration via /reembed works correctly
    </functionality>

    <reliability>
      - Idempotent operations (re-running same URL is safe)
      - Self-healing via lease expiration
      - Graceful handling of missing transcripts
      - Write-new-first prevents data loss on failures
      - Retryable vs terminal errors clearly distinguished
    </reliability>

    <performance>
      - Embedding batch processing efficient
      - Qdrant queries fast with payload indexes
      - Postgres hydration minimal (single query)
      - Health endpoint latency < 100ms
      - Ingest pipeline < 30s for typical video
    </performance>

    <observability>
      - All requests have request_id
      - Structured logs for debugging
      - Health endpoint shows all dependency status
      - Error reasons clear and actionable
      - Job status trackable
    </observability>

    <maintainability>
      - Clean separation: n8n orchestrates, service processes
      - Pluggable providers (embed, llm, rerank)
      - Configuration via environment variables
      - chunk_vectors table supports model evolution
      - Collection naming convention enables clean migrations
    </maintainability>
  </success_criteria>
</project_specification>
